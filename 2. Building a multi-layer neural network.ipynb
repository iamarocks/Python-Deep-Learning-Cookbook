{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "y = data['quality']\n",
    "X = data.drop(['quality'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average quality training set: 5.6231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.080</td>\n",
       "      <td>33.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>9.6</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.091</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99786</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>13.2</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.071</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.00060</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1140            7.3              0.40         0.30             1.7      0.080   \n",
       "920             9.6              0.41         0.37             2.3      0.091   \n",
       "1198            7.7              0.26         0.26             2.0      0.052   \n",
       "423            10.5              0.24         0.47             2.1      0.066   \n",
       "601            13.2              0.46         0.52             2.2      0.071   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1140                 33.0                  79.0  0.99690  3.41       0.65   \n",
       "920                  10.0                  23.0  0.99786  3.24       0.56   \n",
       "1198                 19.0                  77.0  0.99510  3.15       0.79   \n",
       "423                   6.0                  24.0  0.99780  3.15       0.90   \n",
       "601                  12.0                  35.0  1.00060  3.10       0.56   \n",
       "\n",
       "      alcohol  \n",
       "1140      9.5  \n",
       "920      10.5  \n",
       "1198     10.9  \n",
       "423      11.0  \n",
       "601       9.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Average quality training set: {:.4f}'.format(y_train.mean()))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine baseline predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5939855630834515\n"
     ]
    }
   ],
   "source": [
    "# Predict the mean quality of the training data for each validation input\n",
    "print('MSE:', np.mean((y_test - ([y_train.mean()] * y_test.shape[0])) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our neural network by defining the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First hidden layer with 100 hidden units\n",
    "model.add(Dense(200, input_dim=X_train.shape[1], activation='relu')) \n",
    "# Second hidden layer with 50 hidden units\n",
    "model.add(Dense(25, activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# Set optimizer\n",
    "opt = Adam()\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the callback for early stopping and saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "             EarlyStopping(monitor='val_acc', patience=20, verbose=2),\n",
    "             ModelCheckpoint('data/multi_layer_best_model.h5', monitor='val_acc', save_best_only=True, verbose=0)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model with a batch size of 64, 5000 epochs, and a validation split of 20 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1279 samples, validate on 320 samples\n",
      "Epoch 1/5000\n",
      " - 0s - loss: 3.1660 - acc: 0.2275 - val_loss: 2.7110 - val_acc: 0.2625\n",
      "Epoch 2/5000\n",
      " - 0s - loss: 2.3093 - acc: 0.2713 - val_loss: 2.4078 - val_acc: 0.2406\n",
      "Epoch 3/5000\n",
      " - 0s - loss: 1.9772 - acc: 0.2909 - val_loss: 2.0660 - val_acc: 0.2812\n",
      "Epoch 4/5000\n",
      " - 0s - loss: 1.7738 - acc: 0.2932 - val_loss: 1.8961 - val_acc: 0.2750\n",
      "Epoch 5/5000\n",
      " - 0s - loss: 1.6214 - acc: 0.3041 - val_loss: 1.7532 - val_acc: 0.2844\n",
      "Epoch 6/5000\n",
      " - 0s - loss: 1.4854 - acc: 0.3174 - val_loss: 1.6350 - val_acc: 0.3063\n",
      "Epoch 7/5000\n",
      " - 0s - loss: 1.3710 - acc: 0.3276 - val_loss: 1.5448 - val_acc: 0.3156\n",
      "Epoch 8/5000\n",
      " - 0s - loss: 1.2681 - acc: 0.3385 - val_loss: 1.4380 - val_acc: 0.3469\n",
      "Epoch 9/5000\n",
      " - 0s - loss: 1.1728 - acc: 0.3495 - val_loss: 1.3554 - val_acc: 0.3625\n",
      "Epoch 10/5000\n",
      " - 0s - loss: 1.0830 - acc: 0.3675 - val_loss: 1.2725 - val_acc: 0.3594\n",
      "Epoch 11/5000\n",
      " - 0s - loss: 1.0032 - acc: 0.3855 - val_loss: 1.1985 - val_acc: 0.3719\n",
      "Epoch 12/5000\n",
      " - 0s - loss: 0.9322 - acc: 0.4011 - val_loss: 1.1329 - val_acc: 0.4156\n",
      "Epoch 13/5000\n",
      " - 0s - loss: 0.8689 - acc: 0.4277 - val_loss: 1.0553 - val_acc: 0.4219\n",
      "Epoch 14/5000\n",
      " - 0s - loss: 0.8130 - acc: 0.4332 - val_loss: 1.0067 - val_acc: 0.4375\n",
      "Epoch 15/5000\n",
      " - 0s - loss: 0.7679 - acc: 0.4496 - val_loss: 0.9712 - val_acc: 0.4344\n",
      "Epoch 16/5000\n",
      " - 0s - loss: 0.7171 - acc: 0.4652 - val_loss: 0.9040 - val_acc: 0.4500\n",
      "Epoch 17/5000\n",
      " - 0s - loss: 0.6768 - acc: 0.4754 - val_loss: 0.8573 - val_acc: 0.4562\n",
      "Epoch 18/5000\n",
      " - 0s - loss: 0.6375 - acc: 0.4894 - val_loss: 0.8170 - val_acc: 0.4594\n",
      "Epoch 19/5000\n",
      " - 0s - loss: 0.6038 - acc: 0.4996 - val_loss: 0.7736 - val_acc: 0.4594\n",
      "Epoch 20/5000\n",
      " - 0s - loss: 0.5750 - acc: 0.5035 - val_loss: 0.7480 - val_acc: 0.4750\n",
      "Epoch 21/5000\n",
      " - 0s - loss: 0.5454 - acc: 0.5238 - val_loss: 0.7220 - val_acc: 0.5031\n",
      "Epoch 22/5000\n",
      " - 0s - loss: 0.5229 - acc: 0.5238 - val_loss: 0.6862 - val_acc: 0.5125\n",
      "Epoch 23/5000\n",
      " - 0s - loss: 0.4972 - acc: 0.5309 - val_loss: 0.6600 - val_acc: 0.5219\n",
      "Epoch 24/5000\n",
      " - 0s - loss: 0.4828 - acc: 0.5434 - val_loss: 0.6512 - val_acc: 0.5031\n",
      "Epoch 25/5000\n",
      " - 0s - loss: 0.4672 - acc: 0.5504 - val_loss: 0.6006 - val_acc: 0.5281\n",
      "Epoch 26/5000\n",
      " - 0s - loss: 0.4470 - acc: 0.5543 - val_loss: 0.5895 - val_acc: 0.5344\n",
      "Epoch 27/5000\n",
      " - 0s - loss: 0.4327 - acc: 0.5668 - val_loss: 0.5816 - val_acc: 0.5312\n",
      "Epoch 28/5000\n",
      " - 0s - loss: 0.4264 - acc: 0.5668 - val_loss: 0.5538 - val_acc: 0.5531\n",
      "Epoch 29/5000\n",
      " - 0s - loss: 0.4176 - acc: 0.5942 - val_loss: 0.5603 - val_acc: 0.5281\n",
      "Epoch 30/5000\n",
      " - 0s - loss: 0.3994 - acc: 0.5934 - val_loss: 0.5398 - val_acc: 0.5594\n",
      "Epoch 31/5000\n",
      " - 0s - loss: 0.3991 - acc: 0.5880 - val_loss: 0.5424 - val_acc: 0.5531\n",
      "Epoch 32/5000\n",
      " - 0s - loss: 0.3942 - acc: 0.5872 - val_loss: 0.5092 - val_acc: 0.5594\n",
      "Epoch 33/5000\n",
      " - 0s - loss: 0.3808 - acc: 0.6091 - val_loss: 0.5082 - val_acc: 0.5594\n",
      "Epoch 34/5000\n",
      " - 0s - loss: 0.3724 - acc: 0.6106 - val_loss: 0.5098 - val_acc: 0.5594\n",
      "Epoch 35/5000\n",
      " - 0s - loss: 0.3673 - acc: 0.6271 - val_loss: 0.4881 - val_acc: 0.5687\n",
      "Epoch 36/5000\n",
      " - 0s - loss: 0.3613 - acc: 0.6177 - val_loss: 0.4946 - val_acc: 0.5719\n",
      "Epoch 37/5000\n",
      " - 0s - loss: 0.3546 - acc: 0.6294 - val_loss: 0.4769 - val_acc: 0.5719\n",
      "Epoch 38/5000\n",
      " - 0s - loss: 0.3524 - acc: 0.6247 - val_loss: 0.4782 - val_acc: 0.5844\n",
      "Epoch 39/5000\n",
      " - 0s - loss: 0.3479 - acc: 0.6349 - val_loss: 0.4676 - val_acc: 0.5687\n",
      "Epoch 40/5000\n",
      " - 0s - loss: 0.3468 - acc: 0.6364 - val_loss: 0.4587 - val_acc: 0.5625\n",
      "Epoch 41/5000\n",
      " - 0s - loss: 0.3427 - acc: 0.6364 - val_loss: 0.4532 - val_acc: 0.5875\n",
      "Epoch 42/5000\n",
      " - 0s - loss: 0.3390 - acc: 0.6357 - val_loss: 0.4542 - val_acc: 0.5687\n",
      "Epoch 43/5000\n",
      " - 0s - loss: 0.3392 - acc: 0.6380 - val_loss: 0.4543 - val_acc: 0.5875\n",
      "Epoch 44/5000\n",
      " - 0s - loss: 0.3304 - acc: 0.6474 - val_loss: 0.4423 - val_acc: 0.5719\n",
      "Epoch 45/5000\n",
      " - 0s - loss: 0.3290 - acc: 0.6333 - val_loss: 0.4362 - val_acc: 0.6031\n",
      "Epoch 46/5000\n",
      " - 0s - loss: 0.3260 - acc: 0.6466 - val_loss: 0.4590 - val_acc: 0.5781\n",
      "Epoch 47/5000\n",
      " - 0s - loss: 0.3198 - acc: 0.6458 - val_loss: 0.4336 - val_acc: 0.6125\n",
      "Epoch 48/5000\n",
      " - 0s - loss: 0.3228 - acc: 0.6396 - val_loss: 0.4444 - val_acc: 0.5844\n",
      "Epoch 49/5000\n",
      " - 0s - loss: 0.3175 - acc: 0.6622 - val_loss: 0.4322 - val_acc: 0.6031\n",
      "Epoch 50/5000\n",
      " - 0s - loss: 0.3162 - acc: 0.6536 - val_loss: 0.4307 - val_acc: 0.6156\n",
      "Epoch 51/5000\n",
      " - 0s - loss: 0.3131 - acc: 0.6575 - val_loss: 0.4196 - val_acc: 0.5844\n",
      "Epoch 52/5000\n",
      " - 0s - loss: 0.3113 - acc: 0.6607 - val_loss: 0.4235 - val_acc: 0.5844\n",
      "Epoch 53/5000\n",
      " - 0s - loss: 0.3079 - acc: 0.6536 - val_loss: 0.4261 - val_acc: 0.6000\n",
      "Epoch 54/5000\n",
      " - 0s - loss: 0.3062 - acc: 0.6575 - val_loss: 0.4371 - val_acc: 0.6031\n",
      "Epoch 55/5000\n",
      " - 0s - loss: 0.3092 - acc: 0.6615 - val_loss: 0.4339 - val_acc: 0.6031\n",
      "Epoch 56/5000\n",
      " - 0s - loss: 0.3030 - acc: 0.6661 - val_loss: 0.4183 - val_acc: 0.5938\n",
      "Epoch 57/5000\n",
      " - 0s - loss: 0.3140 - acc: 0.6568 - val_loss: 0.4101 - val_acc: 0.6250\n",
      "Epoch 58/5000\n",
      " - 0s - loss: 0.3020 - acc: 0.6669 - val_loss: 0.4072 - val_acc: 0.6312\n",
      "Epoch 59/5000\n",
      " - 0s - loss: 0.3023 - acc: 0.6716 - val_loss: 0.4073 - val_acc: 0.6031\n",
      "Epoch 60/5000\n",
      " - 0s - loss: 0.2965 - acc: 0.6622 - val_loss: 0.4117 - val_acc: 0.6344\n",
      "Epoch 61/5000\n",
      " - 0s - loss: 0.2941 - acc: 0.6685 - val_loss: 0.4001 - val_acc: 0.6062\n",
      "Epoch 62/5000\n",
      " - 0s - loss: 0.2939 - acc: 0.6521 - val_loss: 0.4027 - val_acc: 0.5813\n",
      "Epoch 63/5000\n",
      " - 0s - loss: 0.2974 - acc: 0.6732 - val_loss: 0.4011 - val_acc: 0.6250\n",
      "Epoch 64/5000\n",
      " - 0s - loss: 0.2916 - acc: 0.6708 - val_loss: 0.4044 - val_acc: 0.6281\n",
      "Epoch 65/5000\n",
      " - 0s - loss: 0.2896 - acc: 0.6724 - val_loss: 0.3967 - val_acc: 0.6281\n",
      "Epoch 66/5000\n",
      " - 0s - loss: 0.2911 - acc: 0.6732 - val_loss: 0.4041 - val_acc: 0.6281\n",
      "Epoch 67/5000\n",
      " - 0s - loss: 0.2852 - acc: 0.6771 - val_loss: 0.3934 - val_acc: 0.6281\n",
      "Epoch 68/5000\n",
      " - 0s - loss: 0.2853 - acc: 0.6732 - val_loss: 0.3996 - val_acc: 0.6281\n",
      "Epoch 69/5000\n",
      " - 0s - loss: 0.2810 - acc: 0.6849 - val_loss: 0.3939 - val_acc: 0.6156\n",
      "Epoch 70/5000\n",
      " - 0s - loss: 0.2784 - acc: 0.6724 - val_loss: 0.3965 - val_acc: 0.6125\n",
      "Epoch 71/5000\n",
      " - 0s - loss: 0.2783 - acc: 0.6771 - val_loss: 0.3886 - val_acc: 0.6312\n",
      "Epoch 72/5000\n",
      " - 0s - loss: 0.2729 - acc: 0.6912 - val_loss: 0.4095 - val_acc: 0.6000\n",
      "Epoch 73/5000\n",
      " - 0s - loss: 0.2774 - acc: 0.6763 - val_loss: 0.4048 - val_acc: 0.6062\n",
      "Epoch 74/5000\n",
      " - 0s - loss: 0.2733 - acc: 0.6818 - val_loss: 0.4103 - val_acc: 0.6219\n",
      "Epoch 75/5000\n",
      " - 0s - loss: 0.2719 - acc: 0.6794 - val_loss: 0.3901 - val_acc: 0.6031\n",
      "Epoch 76/5000\n",
      " - 0s - loss: 0.2718 - acc: 0.6904 - val_loss: 0.4011 - val_acc: 0.6000\n",
      "Epoch 77/5000\n",
      " - 0s - loss: 0.2787 - acc: 0.6810 - val_loss: 0.3932 - val_acc: 0.6219\n",
      "Epoch 78/5000\n",
      " - 0s - loss: 0.2710 - acc: 0.6974 - val_loss: 0.3884 - val_acc: 0.6281\n",
      "Epoch 79/5000\n",
      " - 0s - loss: 0.2698 - acc: 0.6880 - val_loss: 0.4065 - val_acc: 0.6156\n",
      "Epoch 80/5000\n",
      " - 0s - loss: 0.2639 - acc: 0.6912 - val_loss: 0.3989 - val_acc: 0.6219\n",
      "Epoch 00080: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2cc27bbe0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, y_train, batch_size=64, epochs=n_epochs, validation_split=0.2, verbose=2, validation_data=(X_test.values, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print the performance on the test set after loading the optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 63.44%\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_model.load_weights('data/multi_layer_best_model.h5')\n",
    "best_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Evaluate on test set\n",
    "score = best_model.evaluate(X_test.values, y_test, verbose=0)\n",
    "print('Test accuracy: %.2f%%' % (score[1]*100))\n",
    "\n",
    "# Test accuracy: 65.62% \n",
    "# Benchmark accuracy on dataset 62.4%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
