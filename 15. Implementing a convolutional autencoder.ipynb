{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data/train_32x32.mat')\n",
    "mat = mat['X']\n",
    "b, h, d, n = mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert all RGB-Images to greyscale\n",
    "img_gray = np.zeros(shape =(n, b, h, 1))\n",
    "\n",
    "def rgb2gray(rgb): \n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "for i in range(n):\n",
    "    #Convert to greyscale\n",
    "    img = rgb2gray(mat[:,:,:,i])\n",
    "    img = img.reshape(1, 32, 32, 1)\n",
    "    img_gray[i,:] = img\n",
    "\n",
    "# Normalize input\n",
    "img_gray = img_gray/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our network architecture for the convolutional autencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_size = Input(shape=(b, h, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(img_size)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(img_size, decoded)\n",
    "autoencoder.compile(optimizer='rmsprop', loss='binary_crossentropy')#, metrics=['binary_accuracy'])\n",
    "\n",
    "# Output summary of network\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the callback function for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyperparameters and start training our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58605 samples, validate on 14652 samples\n",
      "Epoch 1/1000\n",
      "58605/58605 [==============================] - 92s 2ms/step - loss: 0.6404 - val_loss: 0.6295\n",
      "Epoch 2/1000\n",
      "58605/58605 [==============================] - 86s 1ms/step - loss: 0.6277 - val_loss: 0.6230\n",
      "Epoch 3/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6245 - val_loss: 0.6237\n",
      "Epoch 4/1000\n",
      "58605/58605 [==============================] - 113s 2ms/step - loss: 0.6226 - val_loss: 0.6228\n",
      "Epoch 5/1000\n",
      "58605/58605 [==============================] - 118s 2ms/step - loss: 0.6213 - val_loss: 0.6211\n",
      "Epoch 6/1000\n",
      "58605/58605 [==============================] - 124s 2ms/step - loss: 0.6204 - val_loss: 0.6194\n",
      "Epoch 7/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6197 - val_loss: 0.6192\n",
      "Epoch 8/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6192 - val_loss: 0.6190\n",
      "Epoch 9/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6188 - val_loss: 0.6174\n",
      "Epoch 10/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6185 - val_loss: 0.6178\n",
      "Epoch 11/1000\n",
      "58605/58605 [==============================] - 118s 2ms/step - loss: 0.6182 - val_loss: 0.6188\n",
      "Epoch 12/1000\n",
      "58605/58605 [==============================] - 120s 2ms/step - loss: 0.6180 - val_loss: 0.6161\n",
      "Epoch 13/1000\n",
      "58605/58605 [==============================] - 118s 2ms/step - loss: 0.6177 - val_loss: 0.6158\n",
      "Epoch 14/1000\n",
      "58605/58605 [==============================] - 118s 2ms/step - loss: 0.6175 - val_loss: 0.6170\n",
      "Epoch 15/1000\n",
      "58605/58605 [==============================] - 118s 2ms/step - loss: 0.6174 - val_loss: 0.6187\n",
      "Epoch 16/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6172 - val_loss: 0.6156\n",
      "Epoch 17/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6171 - val_loss: 0.6165\n",
      "Epoch 18/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6170 - val_loss: 0.6161\n",
      "Epoch 19/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6169 - val_loss: 0.6195\n",
      "Epoch 20/1000\n",
      "58605/58605 [==============================] - 118s 2ms/step - loss: 0.6169 - val_loss: 0.6148\n",
      "Epoch 21/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6168 - val_loss: 0.6174\n",
      "Epoch 22/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6168 - val_loss: 0.6173\n",
      "Epoch 23/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6168 - val_loss: 0.6159\n",
      "Epoch 24/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6168 - val_loss: 0.6145\n",
      "Epoch 25/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6168 - val_loss: 0.6161\n",
      "Epoch 26/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6168 - val_loss: 0.6162\n",
      "Epoch 27/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6168 - val_loss: 0.6160\n",
      "Epoch 28/1000\n",
      "58605/58605 [==============================] - 117s 2ms/step - loss: 0.6168 - val_loss: 0.6144\n",
      "Epoch 29/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6169 - val_loss: 0.6173\n",
      "Epoch 30/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6169 - val_loss: 0.6152\n",
      "Epoch 31/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6169 - val_loss: 0.6193\n",
      "Epoch 32/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6169 - val_loss: 0.6162\n",
      "Epoch 33/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6170 - val_loss: 0.6155\n",
      "Epoch 34/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6170 - val_loss: 0.6164\n",
      "Epoch 35/1000\n",
      "58605/58605 [==============================] - 117s 2ms/step - loss: 0.6170 - val_loss: 0.6142\n",
      "Epoch 36/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6170 - val_loss: 0.6169\n",
      "Epoch 37/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6171 - val_loss: 0.6161\n",
      "Epoch 38/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6171 - val_loss: 0.6154\n",
      "Epoch 39/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6172 - val_loss: 0.6146\n",
      "Epoch 40/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6173 - val_loss: 0.6142\n",
      "Epoch 41/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6173 - val_loss: 0.6143\n",
      "Epoch 42/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6174 - val_loss: 0.6162\n",
      "Epoch 43/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6174 - val_loss: 0.6145\n",
      "Epoch 44/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6175 - val_loss: 0.6205\n",
      "Epoch 45/1000\n",
      "58605/58605 [==============================] - 113s 2ms/step - loss: 0.6175 - val_loss: 0.6154\n",
      "Epoch 46/1000\n",
      "58605/58605 [==============================] - 113s 2ms/step - loss: 0.6175 - val_loss: 0.6186\n",
      "Epoch 47/1000\n",
      "58605/58605 [==============================] - 115s 2ms/step - loss: 0.6176 - val_loss: 0.6160\n",
      "Epoch 48/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6176 - val_loss: 0.6206\n",
      "Epoch 49/1000\n",
      "58605/58605 [==============================] - 117s 2ms/step - loss: 0.6176 - val_loss: 0.6188\n",
      "Epoch 50/1000\n",
      "58605/58605 [==============================] - 116s 2ms/step - loss: 0.6176 - val_loss: 0.6166\n",
      "Epoch 51/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6177 - val_loss: 0.6216\n",
      "Epoch 52/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6178 - val_loss: 0.6160\n",
      "Epoch 53/1000\n",
      "58605/58605 [==============================] - 113s 2ms/step - loss: 0.6177 - val_loss: 0.6175\n",
      "Epoch 54/1000\n",
      "58605/58605 [==============================] - 113s 2ms/step - loss: 0.6178 - val_loss: 0.6171\n",
      "Epoch 55/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6179 - val_loss: 0.6215\n",
      "Epoch 56/1000\n",
      "58605/58605 [==============================] - 120s 2ms/step - loss: 0.6179 - val_loss: 0.6152\n",
      "Epoch 57/1000\n",
      "58605/58605 [==============================] - 123s 2ms/step - loss: 0.6179 - val_loss: 0.6181\n",
      "Epoch 58/1000\n",
      "58605/58605 [==============================] - 114s 2ms/step - loss: 0.6179 - val_loss: 0.6232\n",
      "Epoch 59/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6180 - val_loss: 0.6156\n",
      "Epoch 60/1000\n",
      "58605/58605 [==============================] - 112s 2ms/step - loss: 0.6180 - val_loss: 0.6158\n",
      "Epoch 61/1000\n",
      "58605/58605 [==============================] - 112s 2ms/step - loss: 0.6181 - val_loss: 0.6168\n",
      "Epoch 62/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6181 - val_loss: 0.6174\n",
      "Epoch 63/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6182 - val_loss: 0.6157\n",
      "Epoch 64/1000\n",
      "58605/58605 [==============================] - 112s 2ms/step - loss: 0.6182 - val_loss: 0.6242\n",
      "Epoch 65/1000\n",
      "58605/58605 [==============================] - 112s 2ms/step - loss: 0.6183 - val_loss: 0.6155\n",
      "Epoch 66/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6183 - val_loss: 0.6199\n",
      "Epoch 67/1000\n",
      "58605/58605 [==============================] - 112s 2ms/step - loss: 0.6183 - val_loss: 0.6244\n",
      "Epoch 68/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6185 - val_loss: 0.6172\n",
      "Epoch 69/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6185 - val_loss: 0.6173\n",
      "Epoch 70/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6185 - val_loss: 0.6159\n",
      "Epoch 71/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6186 - val_loss: 0.6209\n",
      "Epoch 72/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6186 - val_loss: 0.6191\n",
      "Epoch 73/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6186 - val_loss: 0.6206\n",
      "Epoch 74/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6188 - val_loss: 0.6193\n",
      "Epoch 75/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6188 - val_loss: 0.6164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6188 - val_loss: 0.6208\n",
      "Epoch 77/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6188 - val_loss: 0.6251\n",
      "Epoch 78/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6190 - val_loss: 0.6195\n",
      "Epoch 79/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6190 - val_loss: 0.6157\n",
      "Epoch 80/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6191 - val_loss: 0.6160\n",
      "Epoch 81/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6191 - val_loss: 0.6154\n",
      "Epoch 82/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6191 - val_loss: 0.6188\n",
      "Epoch 83/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6191 - val_loss: 0.6194\n",
      "Epoch 84/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6192 - val_loss: 0.6171\n",
      "Epoch 85/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6193 - val_loss: 0.6162\n",
      "Epoch 86/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6194 - val_loss: 0.6181\n",
      "Epoch 87/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6194 - val_loss: 0.6270\n",
      "Epoch 88/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6196 - val_loss: 0.6219\n",
      "Epoch 89/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6196 - val_loss: 0.6186\n",
      "Epoch 90/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6198 - val_loss: 0.6224\n",
      "Epoch 91/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6198 - val_loss: 0.6168\n",
      "Epoch 92/1000\n",
      "58605/58605 [==============================] - 110s 2ms/step - loss: 0.6197 - val_loss: 0.6317\n",
      "Epoch 93/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6198 - val_loss: 0.6166\n",
      "Epoch 94/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6199 - val_loss: 0.6179\n",
      "Epoch 95/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6199 - val_loss: 0.6180\n",
      "Epoch 96/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6201 - val_loss: 0.6220\n",
      "Epoch 97/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6201 - val_loss: 0.6250\n",
      "Epoch 98/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6202 - val_loss: 0.6204\n",
      "Epoch 99/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6203 - val_loss: 0.6150\n",
      "Epoch 100/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6203 - val_loss: 0.6213\n",
      "Epoch 101/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6203 - val_loss: 0.6195\n",
      "Epoch 102/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6205 - val_loss: 0.6166\n",
      "Epoch 103/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6205 - val_loss: 0.6187\n",
      "Epoch 104/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6207 - val_loss: 0.6180\n",
      "Epoch 105/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6206 - val_loss: 0.6206\n",
      "Epoch 106/1000\n",
      "58605/58605 [==============================] - 112s 2ms/step - loss: 0.6208 - val_loss: 0.6161\n",
      "Epoch 107/1000\n",
      "58605/58605 [==============================] - 111s 2ms/step - loss: 0.6207 - val_loss: 0.6171\n",
      "Epoch 108/1000\n",
      "58605/58605 [==============================] - 103s 2ms/step - loss: 0.6209 - val_loss: 0.6194\n",
      "Epoch 109/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6209 - val_loss: 0.6166\n",
      "Epoch 110/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6210 - val_loss: 0.6366\n",
      "Epoch 111/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6211 - val_loss: 0.6256\n",
      "Epoch 112/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6212 - val_loss: 0.6154\n",
      "Epoch 113/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6211 - val_loss: 0.6192\n",
      "Epoch 114/1000\n",
      "58605/58605 [==============================] - 85s 1ms/step - loss: 0.6211 - val_loss: 0.6200\n",
      "Epoch 115/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6213 - val_loss: 0.6161\n",
      "Epoch 116/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6212 - val_loss: 0.6165\n",
      "Epoch 117/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6213 - val_loss: 0.6152\n",
      "Epoch 118/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6214 - val_loss: 0.6172\n",
      "Epoch 119/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6214 - val_loss: 0.6190\n",
      "Epoch 120/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6215 - val_loss: 0.6203\n",
      "Epoch 121/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6216 - val_loss: 0.6252\n",
      "Epoch 122/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6216 - val_loss: 0.6181\n",
      "Epoch 123/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6217 - val_loss: 0.6308\n",
      "Epoch 124/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6216 - val_loss: 0.6176\n",
      "Epoch 125/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6218 - val_loss: 0.6207\n",
      "Epoch 126/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6217 - val_loss: 0.6191\n",
      "Epoch 127/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6218 - val_loss: 0.6180\n",
      "Epoch 128/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6219 - val_loss: 0.6230\n",
      "Epoch 129/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6218 - val_loss: 0.6188\n",
      "Epoch 130/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6220 - val_loss: 0.6181\n",
      "Epoch 131/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6220 - val_loss: 0.6170\n",
      "Epoch 132/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6221 - val_loss: 0.6173\n",
      "Epoch 133/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6221 - val_loss: 0.6191\n",
      "Epoch 134/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6221 - val_loss: 0.6224\n",
      "Epoch 135/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6222 - val_loss: 0.6250\n",
      "Epoch 136/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6223 - val_loss: 0.6291\n",
      "Epoch 137/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6223 - val_loss: 0.6165\n",
      "Epoch 138/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6223 - val_loss: 0.6178\n",
      "Epoch 139/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6224 - val_loss: 0.6167\n",
      "Epoch 140/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6224 - val_loss: 0.6154\n",
      "Epoch 141/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6226 - val_loss: 0.6293\n",
      "Epoch 142/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6224 - val_loss: 0.6203\n",
      "Epoch 143/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6226 - val_loss: 0.6170\n",
      "Epoch 144/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6226 - val_loss: 0.6156\n",
      "Epoch 145/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6227 - val_loss: 0.6194\n",
      "Epoch 146/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6227 - val_loss: 0.6223\n",
      "Epoch 147/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6227 - val_loss: 0.6323\n",
      "Epoch 148/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6228 - val_loss: 0.6223\n",
      "Epoch 149/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6227 - val_loss: 0.6293\n",
      "Epoch 150/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6229 - val_loss: 0.6168\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6228 - val_loss: 0.6357\n",
      "Epoch 152/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6229 - val_loss: 0.6327\n",
      "Epoch 153/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6228 - val_loss: 0.6215\n",
      "Epoch 154/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6230 - val_loss: 0.6431\n",
      "Epoch 155/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6230 - val_loss: 0.6261\n",
      "Epoch 156/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6229 - val_loss: 0.6255\n",
      "Epoch 157/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6230 - val_loss: 0.6275\n",
      "Epoch 158/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6231 - val_loss: 0.6211\n",
      "Epoch 159/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6231 - val_loss: 0.6241\n",
      "Epoch 160/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6232 - val_loss: 0.6189\n",
      "Epoch 161/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6232 - val_loss: 0.6173\n",
      "Epoch 162/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6232 - val_loss: 0.6234\n",
      "Epoch 163/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6232 - val_loss: 0.6188\n",
      "Epoch 164/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6233 - val_loss: 0.6193\n",
      "Epoch 165/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6232 - val_loss: 0.6167\n",
      "Epoch 166/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6233 - val_loss: 0.6409\n",
      "Epoch 167/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6234 - val_loss: 0.6245\n",
      "Epoch 168/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6232 - val_loss: 0.6150\n",
      "Epoch 169/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6235 - val_loss: 0.6180\n",
      "Epoch 170/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6234 - val_loss: 0.6303\n",
      "Epoch 171/1000\n",
      "58605/58605 [==============================] - 63s 1ms/step - loss: 0.6234 - val_loss: 0.6396\n",
      "Epoch 172/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6233 - val_loss: 0.6175\n",
      "Epoch 173/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6233 - val_loss: 0.6164\n",
      "Epoch 174/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6232 - val_loss: 0.6219\n",
      "Epoch 175/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6234 - val_loss: 0.6161\n",
      "Epoch 176/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6233 - val_loss: 0.6177\n",
      "Epoch 177/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6232 - val_loss: 0.6164\n",
      "Epoch 178/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6233 - val_loss: 0.6229\n",
      "Epoch 179/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6232 - val_loss: 0.6172\n",
      "Epoch 180/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6232 - val_loss: 0.6181\n",
      "Epoch 181/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6231 - val_loss: 0.6307\n",
      "Epoch 182/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6231 - val_loss: 0.6152\n",
      "Epoch 183/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6231 - val_loss: 0.6178\n",
      "Epoch 184/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6230 - val_loss: 0.6247\n",
      "Epoch 185/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6231 - val_loss: 0.6207\n",
      "Epoch 186/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6231 - val_loss: 0.6200\n",
      "Epoch 187/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6231 - val_loss: 0.6411\n",
      "Epoch 188/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6229 - val_loss: 0.6210\n",
      "Epoch 189/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6230 - val_loss: 0.6206\n",
      "Epoch 190/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6232 - val_loss: 0.6233\n",
      "Epoch 191/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6229 - val_loss: 0.6246\n",
      "Epoch 192/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6229 - val_loss: 0.6188\n",
      "Epoch 193/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6231 - val_loss: 0.6178\n",
      "Epoch 194/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6230 - val_loss: 0.6194\n",
      "Epoch 195/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6230 - val_loss: 0.6191\n",
      "Epoch 196/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6230 - val_loss: 0.6405\n",
      "Epoch 197/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6231 - val_loss: 0.6185\n",
      "Epoch 198/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6228 - val_loss: 0.6225\n",
      "Epoch 199/1000\n",
      "58605/58605 [==============================] - 57s 977us/step - loss: 0.6229 - val_loss: 0.6170\n",
      "Epoch 200/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6230 - val_loss: 0.6363\n",
      "Epoch 201/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6229 - val_loss: 0.6167\n",
      "Epoch 202/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6230 - val_loss: 0.6172\n",
      "Epoch 203/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6230 - val_loss: 0.6267\n",
      "Epoch 204/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6229 - val_loss: 0.6162\n",
      "Epoch 205/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6229 - val_loss: 0.6179\n",
      "Epoch 206/1000\n",
      "58605/58605 [==============================] - 57s 977us/step - loss: 0.6229 - val_loss: 0.6189\n",
      "Epoch 207/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6229 - val_loss: 0.6189\n",
      "Epoch 208/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6228 - val_loss: 0.6249\n",
      "Epoch 209/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6229 - val_loss: 0.6213\n",
      "Epoch 210/1000\n",
      "58605/58605 [==============================] - 57s 978us/step - loss: 0.6228 - val_loss: 0.6305\n",
      "Epoch 211/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6228 - val_loss: 0.6289\n",
      "Epoch 212/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6229 - val_loss: 0.6216\n",
      "Epoch 213/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6229 - val_loss: 0.6163\n",
      "Epoch 214/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6229 - val_loss: 0.6178\n",
      "Epoch 215/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6229 - val_loss: 0.6165\n",
      "Epoch 216/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6228 - val_loss: 0.6164\n",
      "Epoch 217/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6229 - val_loss: 0.6232\n",
      "Epoch 218/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6229 - val_loss: 0.6185\n",
      "Epoch 219/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6228 - val_loss: 0.6250\n",
      "Epoch 220/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6230 - val_loss: 0.6268\n",
      "Epoch 221/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6229 - val_loss: 0.6356\n",
      "Epoch 222/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6230 - val_loss: 0.6178\n",
      "Epoch 223/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6229 - val_loss: 0.6278\n",
      "Epoch 224/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6228 - val_loss: 0.6257\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6230 - val_loss: 0.6271\n",
      "Epoch 226/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6228 - val_loss: 0.6159\n",
      "Epoch 227/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6228 - val_loss: 0.6184\n",
      "Epoch 228/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6227 - val_loss: 0.6280\n",
      "Epoch 229/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6228 - val_loss: 0.6178\n",
      "Epoch 230/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6227 - val_loss: 0.6191\n",
      "Epoch 231/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6228 - val_loss: 0.6181\n",
      "Epoch 232/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6228 - val_loss: 0.6252\n",
      "Epoch 233/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6226 - val_loss: 0.6293\n",
      "Epoch 234/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6227 - val_loss: 0.6184\n",
      "Epoch 235/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6228 - val_loss: 0.6341\n",
      "Epoch 236/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6229 - val_loss: 0.6183\n",
      "Epoch 237/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6227 - val_loss: 0.6183\n",
      "Epoch 238/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6227 - val_loss: 0.6208\n",
      "Epoch 239/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6229 - val_loss: 0.6354\n",
      "Epoch 240/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6228 - val_loss: 0.6222\n",
      "Epoch 241/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6228 - val_loss: 0.6156\n",
      "Epoch 242/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6229 - val_loss: 0.6390\n",
      "Epoch 243/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6229 - val_loss: 0.6306\n",
      "Epoch 244/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6229 - val_loss: 0.6180\n",
      "Epoch 245/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6229 - val_loss: 0.6252\n",
      "Epoch 246/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6227 - val_loss: 0.6264\n",
      "Epoch 247/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6229 - val_loss: 0.6156\n",
      "Epoch 248/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6229 - val_loss: 0.6231\n",
      "Epoch 249/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6229 - val_loss: 0.6192\n",
      "Epoch 250/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6228 - val_loss: 0.6258\n",
      "Epoch 251/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6228 - val_loss: 0.6158\n",
      "Epoch 252/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6228 - val_loss: 0.6208\n",
      "Epoch 253/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6229 - val_loss: 0.6371\n",
      "Epoch 254/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6231 - val_loss: 0.6165\n",
      "Epoch 255/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6229 - val_loss: 0.6166\n",
      "Epoch 256/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6228 - val_loss: 0.6305\n",
      "Epoch 257/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6230 - val_loss: 0.6181\n",
      "Epoch 258/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6229 - val_loss: 0.6314\n",
      "Epoch 259/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6230 - val_loss: 0.6177\n",
      "Epoch 260/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6228 - val_loss: 0.6284\n",
      "Epoch 261/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6229 - val_loss: 0.6152\n",
      "Epoch 262/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6229 - val_loss: 0.6247\n",
      "Epoch 263/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6229 - val_loss: 0.6149\n",
      "Epoch 264/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6230 - val_loss: 0.6160\n",
      "Epoch 265/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6230 - val_loss: 0.6229\n",
      "Epoch 266/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6230 - val_loss: 0.6189\n",
      "Epoch 267/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6230 - val_loss: 0.6173\n",
      "Epoch 268/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6230 - val_loss: 0.6286\n",
      "Epoch 269/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6229 - val_loss: 0.6162\n",
      "Epoch 270/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6229 - val_loss: 0.6225\n",
      "Epoch 271/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6228 - val_loss: 0.6195\n",
      "Epoch 272/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6230 - val_loss: 0.6195\n",
      "Epoch 273/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6231 - val_loss: 0.6245\n",
      "Epoch 274/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6231 - val_loss: 0.6265\n",
      "Epoch 275/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6231 - val_loss: 0.6249\n",
      "Epoch 276/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6231 - val_loss: 0.6159\n",
      "Epoch 277/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6231 - val_loss: 0.6318\n",
      "Epoch 278/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6230 - val_loss: 0.6279\n",
      "Epoch 279/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6231 - val_loss: 0.6225\n",
      "Epoch 280/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6231 - val_loss: 0.6289\n",
      "Epoch 281/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6231 - val_loss: 0.6155\n",
      "Epoch 282/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6231 - val_loss: 0.6193\n",
      "Epoch 283/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6231 - val_loss: 0.6164\n",
      "Epoch 284/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6231 - val_loss: 0.6319\n",
      "Epoch 285/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6231 - val_loss: 0.6280\n",
      "Epoch 286/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6232 - val_loss: 0.6270\n",
      "Epoch 287/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6232 - val_loss: 0.6159\n",
      "Epoch 288/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6231 - val_loss: 0.6301\n",
      "Epoch 289/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6230 - val_loss: 0.6247\n",
      "Epoch 290/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6234 - val_loss: 0.6239\n",
      "Epoch 291/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6231 - val_loss: 0.6167\n",
      "Epoch 292/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6232 - val_loss: 0.6420\n",
      "Epoch 293/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6234 - val_loss: 0.6221\n",
      "Epoch 294/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6232 - val_loss: 0.6201\n",
      "Epoch 295/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6232 - val_loss: 0.6260\n",
      "Epoch 296/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6232 - val_loss: 0.6158\n",
      "Epoch 297/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6232 - val_loss: 0.6178\n",
      "Epoch 298/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6232 - val_loss: 0.6279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6232 - val_loss: 0.6282\n",
      "Epoch 300/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6233 - val_loss: 0.6238\n",
      "Epoch 301/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6233 - val_loss: 0.6257\n",
      "Epoch 302/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6233 - val_loss: 0.6263\n",
      "Epoch 303/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6232 - val_loss: 0.6176\n",
      "Epoch 304/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6234 - val_loss: 0.6147\n",
      "Epoch 305/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6232 - val_loss: 0.6276\n",
      "Epoch 306/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6232 - val_loss: 0.6237\n",
      "Epoch 307/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6233 - val_loss: 0.6320\n",
      "Epoch 308/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6232 - val_loss: 0.6236\n",
      "Epoch 309/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6234 - val_loss: 0.6246\n",
      "Epoch 310/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6234 - val_loss: 0.6200\n",
      "Epoch 311/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6233 - val_loss: 0.6233\n",
      "Epoch 312/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6233 - val_loss: 0.6152\n",
      "Epoch 313/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6231 - val_loss: 0.6341\n",
      "Epoch 314/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6234 - val_loss: 0.6297\n",
      "Epoch 315/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6233 - val_loss: 0.6207\n",
      "Epoch 316/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6234 - val_loss: 0.6200\n",
      "Epoch 317/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6234 - val_loss: 0.6148\n",
      "Epoch 318/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6233 - val_loss: 0.6235\n",
      "Epoch 319/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6233 - val_loss: 0.6397\n",
      "Epoch 320/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6233 - val_loss: 0.6226\n",
      "Epoch 321/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6235 - val_loss: 0.6259\n",
      "Epoch 322/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6235 - val_loss: 0.6165\n",
      "Epoch 323/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6234 - val_loss: 0.6193\n",
      "Epoch 324/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6233 - val_loss: 0.6357\n",
      "Epoch 325/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6234 - val_loss: 0.6251\n",
      "Epoch 326/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6235 - val_loss: 0.6162\n",
      "Epoch 327/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6236 - val_loss: 0.6203\n",
      "Epoch 328/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6235 - val_loss: 0.6218\n",
      "Epoch 329/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6235 - val_loss: 0.6161\n",
      "Epoch 330/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6235 - val_loss: 0.6280\n",
      "Epoch 331/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6235 - val_loss: 0.6204\n",
      "Epoch 332/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6235 - val_loss: 0.6181\n",
      "Epoch 333/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6235 - val_loss: 0.6263\n",
      "Epoch 334/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6235 - val_loss: 0.6174\n",
      "Epoch 335/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6236 - val_loss: 0.6173\n",
      "Epoch 336/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6236 - val_loss: 0.6427\n",
      "Epoch 337/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6238 - val_loss: 0.6210\n",
      "Epoch 338/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6237 - val_loss: 0.6167\n",
      "Epoch 339/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6236 - val_loss: 0.6145\n",
      "Epoch 340/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6238 - val_loss: 0.6164\n",
      "Epoch 341/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6237 - val_loss: 0.6307\n",
      "Epoch 342/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6237 - val_loss: 0.6235\n",
      "Epoch 343/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6237 - val_loss: 0.6164\n",
      "Epoch 344/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6236 - val_loss: 0.6207\n",
      "Epoch 345/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6237 - val_loss: 0.6148\n",
      "Epoch 346/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6238 - val_loss: 0.6170\n",
      "Epoch 347/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6237 - val_loss: 0.6469\n",
      "Epoch 348/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6237 - val_loss: 0.6153\n",
      "Epoch 349/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6237 - val_loss: 0.6158\n",
      "Epoch 350/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6238 - val_loss: 0.6216\n",
      "Epoch 351/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6237 - val_loss: 0.6152\n",
      "Epoch 352/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6239 - val_loss: 0.6175\n",
      "Epoch 353/1000\n",
      "58605/58605 [==============================] - 58s 982us/step - loss: 0.6238 - val_loss: 0.6313\n",
      "Epoch 354/1000\n",
      "58605/58605 [==============================] - 59s 1ms/step - loss: 0.6237 - val_loss: 0.6223\n",
      "Epoch 355/1000\n",
      "58605/58605 [==============================] - 61s 1ms/step - loss: 0.6238 - val_loss: 0.6192\n",
      "Epoch 356/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6240 - val_loss: 0.6330\n",
      "Epoch 357/1000\n",
      "58605/58605 [==============================] - 64s 1ms/step - loss: 0.6239 - val_loss: 0.6322\n",
      "Epoch 358/1000\n",
      "58605/58605 [==============================] - 64s 1ms/step - loss: 0.6239 - val_loss: 0.6168\n",
      "Epoch 359/1000\n",
      "58605/58605 [==============================] - 65s 1ms/step - loss: 0.6239 - val_loss: 0.6226\n",
      "Epoch 360/1000\n",
      "58605/58605 [==============================] - 63s 1ms/step - loss: 0.6239 - val_loss: 0.6196\n",
      "Epoch 361/1000\n",
      "58605/58605 [==============================] - 63s 1ms/step - loss: 0.6239 - val_loss: 0.6182\n",
      "Epoch 362/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6238 - val_loss: 0.6217\n",
      "Epoch 363/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6239 - val_loss: 0.6205\n",
      "Epoch 364/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6239 - val_loss: 0.6315\n",
      "Epoch 365/1000\n",
      "58605/58605 [==============================] - 63s 1ms/step - loss: 0.6240 - val_loss: 0.6175\n",
      "Epoch 366/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6240 - val_loss: 0.6220\n",
      "Epoch 367/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6241 - val_loss: 0.6191\n",
      "Epoch 368/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6241 - val_loss: 0.6277\n",
      "Epoch 369/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6240 - val_loss: 0.6317\n",
      "Epoch 370/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6241 - val_loss: 0.6146\n",
      "Epoch 371/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6241 - val_loss: 0.6192\n",
      "Epoch 372/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6241 - val_loss: 0.6179\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6241 - val_loss: 0.6330\n",
      "Epoch 374/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6242 - val_loss: 0.6188\n",
      "Epoch 375/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6240 - val_loss: 0.6159\n",
      "Epoch 376/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6243 - val_loss: 0.6237\n",
      "Epoch 377/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6240 - val_loss: 0.6255\n",
      "Epoch 378/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6241 - val_loss: 0.6225\n",
      "Epoch 379/1000\n",
      "58605/58605 [==============================] - 62s 1ms/step - loss: 0.6242 - val_loss: 0.6283\n",
      "Epoch 380/1000\n",
      "58605/58605 [==============================] - 60s 1ms/step - loss: 0.6241 - val_loss: 0.6150\n",
      "Epoch 381/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6241 - val_loss: 0.6198\n",
      "Epoch 382/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6240 - val_loss: 0.6228\n",
      "Epoch 383/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6243 - val_loss: 0.6211\n",
      "Epoch 384/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6242 - val_loss: 0.6480\n",
      "Epoch 385/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6242 - val_loss: 0.6421\n",
      "Epoch 386/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6243 - val_loss: 0.6213\n",
      "Epoch 387/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6243 - val_loss: 0.6186\n",
      "Epoch 388/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6242 - val_loss: 0.6219\n",
      "Epoch 389/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6243 - val_loss: 0.6297\n",
      "Epoch 390/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6243 - val_loss: 0.6238\n",
      "Epoch 391/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6243 - val_loss: 0.6310\n",
      "Epoch 392/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6242 - val_loss: 0.6329\n",
      "Epoch 393/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6243 - val_loss: 0.6201\n",
      "Epoch 394/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6243 - val_loss: 0.6181\n",
      "Epoch 395/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6243 - val_loss: 0.6326\n",
      "Epoch 396/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6244 - val_loss: 0.6209\n",
      "Epoch 397/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6243 - val_loss: 0.6173\n",
      "Epoch 398/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6245 - val_loss: 0.6239\n",
      "Epoch 399/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6243 - val_loss: 0.6488\n",
      "Epoch 400/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6244 - val_loss: 0.6233\n",
      "Epoch 401/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6244 - val_loss: 0.6197\n",
      "Epoch 402/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6244 - val_loss: 0.6203\n",
      "Epoch 403/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6244 - val_loss: 0.6165\n",
      "Epoch 404/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6246 - val_loss: 0.6246\n",
      "Epoch 405/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6245 - val_loss: 0.6153\n",
      "Epoch 406/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6243 - val_loss: 0.6184\n",
      "Epoch 407/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6245 - val_loss: 0.6156\n",
      "Epoch 408/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6244 - val_loss: 0.6270\n",
      "Epoch 409/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6245 - val_loss: 0.6187\n",
      "Epoch 410/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6245 - val_loss: 0.6208\n",
      "Epoch 411/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6244 - val_loss: 0.6233\n",
      "Epoch 412/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6246 - val_loss: 0.6248\n",
      "Epoch 413/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6245 - val_loss: 0.6302\n",
      "Epoch 414/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6245 - val_loss: 0.6319\n",
      "Epoch 415/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6246 - val_loss: 0.6321\n",
      "Epoch 416/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6246 - val_loss: 0.6275\n",
      "Epoch 417/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6245 - val_loss: 0.6143\n",
      "Epoch 418/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6247 - val_loss: 0.6153\n",
      "Epoch 419/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6246 - val_loss: 0.6149\n",
      "Epoch 420/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6246 - val_loss: 0.6329\n",
      "Epoch 421/1000\n",
      "58605/58605 [==============================] - 57s 980us/step - loss: 0.6247 - val_loss: 0.6241\n",
      "Epoch 422/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6249 - val_loss: 0.6172\n",
      "Epoch 423/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6246 - val_loss: 0.6283\n",
      "Epoch 424/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6246 - val_loss: 0.6245\n",
      "Epoch 425/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6248 - val_loss: 0.6228\n",
      "Epoch 426/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6246 - val_loss: 0.6469\n",
      "Epoch 427/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6248 - val_loss: 0.6190\n",
      "Epoch 428/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6247 - val_loss: 0.6287\n",
      "Epoch 429/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6248 - val_loss: 0.6329\n",
      "Epoch 430/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6248 - val_loss: 0.6181\n",
      "Epoch 431/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6248 - val_loss: 0.6371\n",
      "Epoch 432/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6249 - val_loss: 0.6233\n",
      "Epoch 433/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6249 - val_loss: 0.6170\n",
      "Epoch 434/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6248 - val_loss: 0.6210\n",
      "Epoch 435/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6248 - val_loss: 0.6194\n",
      "Epoch 436/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6250 - val_loss: 0.6179\n",
      "Epoch 437/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6248 - val_loss: 0.6399\n",
      "Epoch 438/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6250 - val_loss: 0.6156\n",
      "Epoch 439/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6248 - val_loss: 0.6173\n",
      "Epoch 440/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6248 - val_loss: 0.6206\n",
      "Epoch 441/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6248 - val_loss: 0.6180\n",
      "Epoch 442/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6249 - val_loss: 0.6294\n",
      "Epoch 443/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6249 - val_loss: 0.6277\n",
      "Epoch 444/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6250 - val_loss: 0.6227\n",
      "Epoch 445/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6251 - val_loss: 0.6170\n",
      "Epoch 446/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6251 - val_loss: 0.6364\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6251 - val_loss: 0.6164\n",
      "Epoch 448/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6251 - val_loss: 0.6200\n",
      "Epoch 449/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6250 - val_loss: 0.6185\n",
      "Epoch 450/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6250 - val_loss: 0.6193\n",
      "Epoch 451/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6251 - val_loss: 0.6175\n",
      "Epoch 452/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6249 - val_loss: 0.6329\n",
      "Epoch 453/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6251 - val_loss: 0.6212\n",
      "Epoch 454/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6249 - val_loss: 0.6298\n",
      "Epoch 455/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6254 - val_loss: 0.6178\n",
      "Epoch 456/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6249 - val_loss: 0.6246\n",
      "Epoch 457/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6252 - val_loss: 0.6199\n",
      "Epoch 458/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6249 - val_loss: 0.6165\n",
      "Epoch 459/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6252 - val_loss: 0.6318\n",
      "Epoch 460/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6251 - val_loss: 0.6338\n",
      "Epoch 461/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6253 - val_loss: 0.6186\n",
      "Epoch 462/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6252 - val_loss: 0.6160\n",
      "Epoch 463/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6251 - val_loss: 0.6189\n",
      "Epoch 464/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6253 - val_loss: 0.6161\n",
      "Epoch 465/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6253 - val_loss: 0.6275\n",
      "Epoch 466/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6251 - val_loss: 0.6179\n",
      "Epoch 467/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6251 - val_loss: 0.6214\n",
      "Epoch 468/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6251 - val_loss: 0.6191\n",
      "Epoch 469/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6253 - val_loss: 0.6225\n",
      "Epoch 470/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6252 - val_loss: 0.6555\n",
      "Epoch 471/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6252 - val_loss: 0.6280\n",
      "Epoch 472/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6252 - val_loss: 0.6337\n",
      "Epoch 473/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6252 - val_loss: 0.6382\n",
      "Epoch 474/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6251 - val_loss: 0.6434\n",
      "Epoch 475/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6253 - val_loss: 0.6230\n",
      "Epoch 476/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6255 - val_loss: 0.6255\n",
      "Epoch 477/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6252 - val_loss: 0.6260\n",
      "Epoch 478/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6254 - val_loss: 0.6456\n",
      "Epoch 479/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6253 - val_loss: 0.6353\n",
      "Epoch 480/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6255 - val_loss: 0.6288\n",
      "Epoch 481/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6255 - val_loss: 0.6234\n",
      "Epoch 482/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6254 - val_loss: 0.6189\n",
      "Epoch 483/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6254 - val_loss: 0.6291\n",
      "Epoch 484/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6256 - val_loss: 0.6210\n",
      "Epoch 485/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6254 - val_loss: 0.6338\n",
      "Epoch 486/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6256 - val_loss: 0.6301\n",
      "Epoch 487/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6255 - val_loss: 0.6297\n",
      "Epoch 488/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6255 - val_loss: 0.6259\n",
      "Epoch 489/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6255 - val_loss: 0.6235\n",
      "Epoch 490/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6255 - val_loss: 0.6250\n",
      "Epoch 491/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6256 - val_loss: 0.6182\n",
      "Epoch 492/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6253 - val_loss: 0.6289\n",
      "Epoch 493/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6256 - val_loss: 0.6174\n",
      "Epoch 494/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6255 - val_loss: 0.6235\n",
      "Epoch 495/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6256 - val_loss: 0.6278\n",
      "Epoch 496/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6257 - val_loss: 0.6153\n",
      "Epoch 497/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6257 - val_loss: 0.6276\n",
      "Epoch 498/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6255 - val_loss: 0.6161\n",
      "Epoch 499/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6256 - val_loss: 0.6182\n",
      "Epoch 500/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6254 - val_loss: 0.6230\n",
      "Epoch 501/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6257 - val_loss: 0.6177\n",
      "Epoch 502/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6257 - val_loss: 0.6208\n",
      "Epoch 503/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6255 - val_loss: 0.6317\n",
      "Epoch 504/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6258 - val_loss: 0.6189\n",
      "Epoch 505/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6257 - val_loss: 0.6308\n",
      "Epoch 506/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6257 - val_loss: 0.6289\n",
      "Epoch 507/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6255 - val_loss: 0.6377\n",
      "Epoch 508/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6258 - val_loss: 0.6419\n",
      "Epoch 509/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6258 - val_loss: 0.6319\n",
      "Epoch 510/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6257 - val_loss: 0.6351\n",
      "Epoch 511/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6259 - val_loss: 0.6162\n",
      "Epoch 512/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6257 - val_loss: 0.6180\n",
      "Epoch 513/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6258 - val_loss: 0.6218\n",
      "Epoch 514/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6259 - val_loss: 0.6164\n",
      "Epoch 515/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6260 - val_loss: 0.6320\n",
      "Epoch 516/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6259 - val_loss: 0.6490\n",
      "Epoch 517/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6258 - val_loss: 0.6199\n",
      "Epoch 518/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6259 - val_loss: 0.6330\n",
      "Epoch 519/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6258 - val_loss: 0.6266\n",
      "Epoch 520/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6257 - val_loss: 0.6234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6260 - val_loss: 0.6191\n",
      "Epoch 522/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6259 - val_loss: 0.6193\n",
      "Epoch 523/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6259 - val_loss: 0.6174\n",
      "Epoch 524/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6259 - val_loss: 0.6162\n",
      "Epoch 525/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6261 - val_loss: 0.6258\n",
      "Epoch 526/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6260 - val_loss: 0.6236\n",
      "Epoch 527/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6261 - val_loss: 0.6254\n",
      "Epoch 528/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6256 - val_loss: 0.6511\n",
      "Epoch 529/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6262 - val_loss: 0.6442\n",
      "Epoch 530/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6261 - val_loss: 0.6227\n",
      "Epoch 531/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6262 - val_loss: 0.6223\n",
      "Epoch 532/1000\n",
      "58605/58605 [==============================] - 58s 990us/step - loss: 0.6262 - val_loss: 0.6203\n",
      "Epoch 533/1000\n",
      "58605/58605 [==============================] - 63s 1ms/step - loss: 0.6261 - val_loss: 0.6293\n",
      "Epoch 534/1000\n",
      "58605/58605 [==============================] - 65s 1ms/step - loss: 0.6260 - val_loss: 0.6159\n",
      "Epoch 535/1000\n",
      "58605/58605 [==============================] - 65s 1ms/step - loss: 0.6261 - val_loss: 0.6168\n",
      "Epoch 536/1000\n",
      "58605/58605 [==============================] - 63s 1ms/step - loss: 0.6262 - val_loss: 0.6177\n",
      "Epoch 537/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6262 - val_loss: 0.6181\n",
      "Epoch 538/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6260 - val_loss: 0.6357\n",
      "Epoch 539/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6260 - val_loss: 0.6183\n",
      "Epoch 540/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6261 - val_loss: 0.6380\n",
      "Epoch 541/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6262 - val_loss: 0.6381\n",
      "Epoch 542/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6262 - val_loss: 0.6173\n",
      "Epoch 543/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6261 - val_loss: 0.6231\n",
      "Epoch 544/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6263 - val_loss: 0.6211\n",
      "Epoch 545/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6260 - val_loss: 0.6312\n",
      "Epoch 546/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6263 - val_loss: 0.6485\n",
      "Epoch 547/1000\n",
      "58605/58605 [==============================] - 57s 979us/step - loss: 0.6264 - val_loss: 0.6207\n",
      "Epoch 548/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6264 - val_loss: 0.6234\n",
      "Epoch 549/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6263 - val_loss: 0.6208\n",
      "Epoch 550/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6264 - val_loss: 0.6267\n",
      "Epoch 551/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6261 - val_loss: 0.6194\n",
      "Epoch 552/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6263 - val_loss: 0.6238\n",
      "Epoch 553/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6263 - val_loss: 0.6203\n",
      "Epoch 554/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6263 - val_loss: 0.6179\n",
      "Epoch 555/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6263 - val_loss: 0.6310\n",
      "Epoch 556/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6263 - val_loss: 0.6205\n",
      "Epoch 557/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6264 - val_loss: 0.6378\n",
      "Epoch 558/1000\n",
      "58605/58605 [==============================] - 57s 977us/step - loss: 0.6265 - val_loss: 0.6191\n",
      "Epoch 559/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6264 - val_loss: 0.6175\n",
      "Epoch 560/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6263 - val_loss: 0.6182\n",
      "Epoch 561/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6264 - val_loss: 0.6335\n",
      "Epoch 562/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6265 - val_loss: 0.6177\n",
      "Epoch 563/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6265 - val_loss: 0.6506\n",
      "Epoch 564/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6265 - val_loss: 0.6190\n",
      "Epoch 565/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6267 - val_loss: 0.6267\n",
      "Epoch 566/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6265 - val_loss: 0.6169\n",
      "Epoch 567/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6268 - val_loss: 0.6171\n",
      "Epoch 568/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6267 - val_loss: 0.6298\n",
      "Epoch 569/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6266 - val_loss: 0.6189\n",
      "Epoch 570/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6266 - val_loss: 0.6184\n",
      "Epoch 571/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6267 - val_loss: 0.6361\n",
      "Epoch 572/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6267 - val_loss: 0.6348\n",
      "Epoch 573/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6265 - val_loss: 0.6180\n",
      "Epoch 574/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6266 - val_loss: 0.6377\n",
      "Epoch 575/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6267 - val_loss: 0.6348\n",
      "Epoch 576/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6268 - val_loss: 0.6186\n",
      "Epoch 577/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6266 - val_loss: 0.6315\n",
      "Epoch 578/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6269 - val_loss: 0.6509\n",
      "Epoch 579/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6265 - val_loss: 0.6235\n",
      "Epoch 580/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6268 - val_loss: 0.6332\n",
      "Epoch 581/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6269 - val_loss: 0.6283\n",
      "Epoch 582/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6268 - val_loss: 0.6294\n",
      "Epoch 583/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6268 - val_loss: 0.6275\n",
      "Epoch 584/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6268 - val_loss: 0.6235\n",
      "Epoch 585/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6268 - val_loss: 0.6214\n",
      "Epoch 586/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6269 - val_loss: 0.6310\n",
      "Epoch 587/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6270 - val_loss: 0.6252\n",
      "Epoch 588/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6269 - val_loss: 0.6270\n",
      "Epoch 589/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6267 - val_loss: 0.6210\n",
      "Epoch 590/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6270 - val_loss: 0.6210\n",
      "Epoch 591/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6269 - val_loss: 0.6225\n",
      "Epoch 592/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6269 - val_loss: 0.6362\n",
      "Epoch 593/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6271 - val_loss: 0.6529\n",
      "Epoch 594/1000\n",
      "58605/58605 [==============================] - 57s 977us/step - loss: 0.6271 - val_loss: 0.6307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6270 - val_loss: 0.6384\n",
      "Epoch 596/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6270 - val_loss: 0.6278\n",
      "Epoch 597/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6270 - val_loss: 0.6309\n",
      "Epoch 598/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6271 - val_loss: 0.6225\n",
      "Epoch 599/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6270 - val_loss: 0.6221\n",
      "Epoch 600/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6274 - val_loss: 0.6226\n",
      "Epoch 601/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6271 - val_loss: 0.6172\n",
      "Epoch 602/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6272 - val_loss: 0.6401\n",
      "Epoch 603/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6273 - val_loss: 0.6339\n",
      "Epoch 604/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6276 - val_loss: 0.6316\n",
      "Epoch 605/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6271 - val_loss: 0.6333\n",
      "Epoch 606/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6272 - val_loss: 0.6546\n",
      "Epoch 607/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6272 - val_loss: 0.6296\n",
      "Epoch 608/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6272 - val_loss: 0.6319\n",
      "Epoch 609/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6271 - val_loss: 0.6417\n",
      "Epoch 610/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6274 - val_loss: 0.6183\n",
      "Epoch 611/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6274 - val_loss: 0.6260\n",
      "Epoch 612/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6275 - val_loss: 0.6208\n",
      "Epoch 613/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6272 - val_loss: 0.6239\n",
      "Epoch 614/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6273 - val_loss: 0.6395\n",
      "Epoch 615/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6274 - val_loss: 0.6227\n",
      "Epoch 616/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6275 - val_loss: 0.6259\n",
      "Epoch 617/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6275 - val_loss: 0.6261\n",
      "Epoch 618/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6275 - val_loss: 0.6181\n",
      "Epoch 619/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6275 - val_loss: 0.6207\n",
      "Epoch 620/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6275 - val_loss: 0.6203\n",
      "Epoch 621/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6273 - val_loss: 0.6272\n",
      "Epoch 622/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6275 - val_loss: 0.6337\n",
      "Epoch 623/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6274 - val_loss: 0.6415\n",
      "Epoch 624/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6275 - val_loss: 0.6175\n",
      "Epoch 625/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6275 - val_loss: 0.6267\n",
      "Epoch 626/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6274 - val_loss: 0.6292\n",
      "Epoch 627/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6272 - val_loss: 0.6381\n",
      "Epoch 628/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6275 - val_loss: 0.6204\n",
      "Epoch 629/1000\n",
      "58605/58605 [==============================] - 57s 978us/step - loss: 0.6274 - val_loss: 0.6210\n",
      "Epoch 630/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6276 - val_loss: 0.6197\n",
      "Epoch 631/1000\n",
      "58605/58605 [==============================] - 58s 997us/step - loss: 0.6275 - val_loss: 0.6216\n",
      "Epoch 632/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6276 - val_loss: 0.6324\n",
      "Epoch 633/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6276 - val_loss: 0.6217\n",
      "Epoch 634/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6277 - val_loss: 0.6429\n",
      "Epoch 635/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6278 - val_loss: 0.6171\n",
      "Epoch 636/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6277 - val_loss: 0.6244\n",
      "Epoch 637/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6276 - val_loss: 0.6280\n",
      "Epoch 638/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6276 - val_loss: 0.6588\n",
      "Epoch 639/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6278 - val_loss: 0.6177\n",
      "Epoch 640/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6277 - val_loss: 0.6215\n",
      "Epoch 641/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6276 - val_loss: 0.6349\n",
      "Epoch 642/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6276 - val_loss: 0.6273\n",
      "Epoch 643/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6277 - val_loss: 0.6289\n",
      "Epoch 644/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6280 - val_loss: 0.6161\n",
      "Epoch 645/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6279 - val_loss: 0.6174\n",
      "Epoch 646/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6277 - val_loss: 0.6389\n",
      "Epoch 647/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6278 - val_loss: 0.6535\n",
      "Epoch 648/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6278 - val_loss: 0.6164\n",
      "Epoch 649/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6278 - val_loss: 0.6254\n",
      "Epoch 650/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6282 - val_loss: 0.6246\n",
      "Epoch 651/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6282 - val_loss: 0.6179\n",
      "Epoch 652/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6281 - val_loss: 0.6353\n",
      "Epoch 653/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6278 - val_loss: 0.6201\n",
      "Epoch 654/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6281 - val_loss: 0.6177\n",
      "Epoch 655/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6277 - val_loss: 0.6192\n",
      "Epoch 656/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6278 - val_loss: 0.6186\n",
      "Epoch 657/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6284 - val_loss: 0.6190\n",
      "Epoch 658/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6276 - val_loss: 0.6190\n",
      "Epoch 659/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6279 - val_loss: 0.6269\n",
      "Epoch 660/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6281 - val_loss: 0.6245\n",
      "Epoch 661/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6281 - val_loss: 0.6193\n",
      "Epoch 662/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6280 - val_loss: 0.6263\n",
      "Epoch 663/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6280 - val_loss: 0.6195\n",
      "Epoch 664/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6280 - val_loss: 0.6295\n",
      "Epoch 665/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6282 - val_loss: 0.6290\n",
      "Epoch 666/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6279 - val_loss: 0.6378\n",
      "Epoch 667/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6281 - val_loss: 0.6204\n",
      "Epoch 668/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6283 - val_loss: 0.6380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6281 - val_loss: 0.6222\n",
      "Epoch 670/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6283 - val_loss: 0.6390\n",
      "Epoch 671/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6282 - val_loss: 0.6330\n",
      "Epoch 672/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6281 - val_loss: 0.6298\n",
      "Epoch 673/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6279 - val_loss: 0.6381\n",
      "Epoch 674/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6284 - val_loss: 0.6300\n",
      "Epoch 675/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6281 - val_loss: 0.6191\n",
      "Epoch 676/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6282 - val_loss: 0.6204\n",
      "Epoch 677/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6283 - val_loss: 0.6296\n",
      "Epoch 678/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6282 - val_loss: 0.6249\n",
      "Epoch 679/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6281 - val_loss: 0.6225\n",
      "Epoch 680/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6286 - val_loss: 0.6225\n",
      "Epoch 681/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6282 - val_loss: 0.6216\n",
      "Epoch 682/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6282 - val_loss: 0.6315\n",
      "Epoch 683/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6282 - val_loss: 0.6201\n",
      "Epoch 684/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6282 - val_loss: 0.6204\n",
      "Epoch 685/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6283 - val_loss: 0.6267\n",
      "Epoch 686/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6285 - val_loss: 0.6412\n",
      "Epoch 687/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6286 - val_loss: 0.6196\n",
      "Epoch 688/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6284 - val_loss: 0.6433\n",
      "Epoch 689/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6284 - val_loss: 0.6195\n",
      "Epoch 690/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6284 - val_loss: 0.6365\n",
      "Epoch 691/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6283 - val_loss: 0.6262\n",
      "Epoch 692/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6283 - val_loss: 0.6231\n",
      "Epoch 693/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6283 - val_loss: 0.6182\n",
      "Epoch 694/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6285 - val_loss: 0.6206\n",
      "Epoch 695/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6286 - val_loss: 0.6218\n",
      "Epoch 696/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6281 - val_loss: 0.6257\n",
      "Epoch 697/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6282 - val_loss: 0.6207\n",
      "Epoch 698/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6285 - val_loss: 0.6190\n",
      "Epoch 699/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6284 - val_loss: 0.6306\n",
      "Epoch 700/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6285 - val_loss: 0.6207\n",
      "Epoch 701/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6286 - val_loss: 0.6375\n",
      "Epoch 702/1000\n",
      "58605/58605 [==============================] - 57s 977us/step - loss: 0.6287 - val_loss: 0.6347\n",
      "Epoch 703/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6286 - val_loss: 0.6235\n",
      "Epoch 704/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6285 - val_loss: 0.6248\n",
      "Epoch 705/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6286 - val_loss: 0.6167\n",
      "Epoch 706/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6287 - val_loss: 0.6399\n",
      "Epoch 707/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6287 - val_loss: 0.6218\n",
      "Epoch 708/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6285 - val_loss: 0.6288\n",
      "Epoch 709/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6286 - val_loss: 0.6263\n",
      "Epoch 710/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6286 - val_loss: 0.6242\n",
      "Epoch 711/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6285 - val_loss: 0.6426\n",
      "Epoch 712/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6285 - val_loss: 0.6419\n",
      "Epoch 713/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6286 - val_loss: 0.6316\n",
      "Epoch 714/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6287 - val_loss: 0.6365\n",
      "Epoch 715/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6287 - val_loss: 0.6301\n",
      "Epoch 716/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6290 - val_loss: 0.6563\n",
      "Epoch 717/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6289 - val_loss: 0.6601\n",
      "Epoch 718/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6288 - val_loss: 0.6329\n",
      "Epoch 719/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6288 - val_loss: 0.6209\n",
      "Epoch 720/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6288 - val_loss: 0.6187\n",
      "Epoch 721/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6290 - val_loss: 0.6366\n",
      "Epoch 722/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6289 - val_loss: 0.6261\n",
      "Epoch 723/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6291 - val_loss: 0.6265\n",
      "Epoch 724/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6292 - val_loss: 0.6192\n",
      "Epoch 725/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6289 - val_loss: 0.6567\n",
      "Epoch 726/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6288 - val_loss: 0.6474\n",
      "Epoch 727/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6290 - val_loss: 0.6199\n",
      "Epoch 728/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6294 - val_loss: 0.6216\n",
      "Epoch 729/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6287 - val_loss: 0.6404\n",
      "Epoch 730/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6287 - val_loss: 0.6468\n",
      "Epoch 731/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6290 - val_loss: 0.6222\n",
      "Epoch 732/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6290 - val_loss: 0.6456\n",
      "Epoch 733/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6287 - val_loss: 0.6242\n",
      "Epoch 734/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6294 - val_loss: 0.6481\n",
      "Epoch 735/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6291 - val_loss: 0.6274\n",
      "Epoch 736/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6290 - val_loss: 0.6474\n",
      "Epoch 737/1000\n",
      "58605/58605 [==============================] - 57s 979us/step - loss: 0.6292 - val_loss: 0.6308\n",
      "Epoch 738/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6292 - val_loss: 0.6176\n",
      "Epoch 739/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6291 - val_loss: 0.6201\n",
      "Epoch 740/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6291 - val_loss: 0.6241\n",
      "Epoch 741/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6289 - val_loss: 0.6394\n",
      "Epoch 742/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6293 - val_loss: 0.6259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6293 - val_loss: 0.6213\n",
      "Epoch 744/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6293 - val_loss: 0.6279\n",
      "Epoch 745/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6296 - val_loss: 0.6329\n",
      "Epoch 746/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6294 - val_loss: 0.6297\n",
      "Epoch 747/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6293 - val_loss: 0.6230\n",
      "Epoch 748/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6293 - val_loss: 0.6367\n",
      "Epoch 749/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6295 - val_loss: 0.6590\n",
      "Epoch 750/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6291 - val_loss: 0.6216\n",
      "Epoch 751/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6292 - val_loss: 0.6340\n",
      "Epoch 752/1000\n",
      "58605/58605 [==============================] - 57s 975us/step - loss: 0.6293 - val_loss: 0.6195\n",
      "Epoch 753/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6294 - val_loss: 0.6237\n",
      "Epoch 754/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6291 - val_loss: 0.6426\n",
      "Epoch 755/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6293 - val_loss: 0.6199\n",
      "Epoch 756/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6293 - val_loss: 0.6245\n",
      "Epoch 757/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6294 - val_loss: 0.6215\n",
      "Epoch 758/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6293 - val_loss: 0.6214\n",
      "Epoch 759/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6295 - val_loss: 0.6203\n",
      "Epoch 760/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6298 - val_loss: 0.6248\n",
      "Epoch 761/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6297 - val_loss: 0.6376\n",
      "Epoch 762/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6294 - val_loss: 0.6248\n",
      "Epoch 763/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6295 - val_loss: 0.6206\n",
      "Epoch 764/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6294 - val_loss: 0.6191\n",
      "Epoch 765/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6293 - val_loss: 0.6403\n",
      "Epoch 766/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6297 - val_loss: 0.6186\n",
      "Epoch 767/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6293 - val_loss: 0.6190\n",
      "Epoch 768/1000\n",
      "58605/58605 [==============================] - 58s 991us/step - loss: 0.6294 - val_loss: 0.6206\n",
      "Epoch 769/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6297 - val_loss: 0.6328\n",
      "Epoch 770/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6296 - val_loss: 0.6419\n",
      "Epoch 771/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6297 - val_loss: 0.6429\n",
      "Epoch 772/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6296 - val_loss: 0.6326\n",
      "Epoch 773/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6298 - val_loss: 0.6374\n",
      "Epoch 774/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6299 - val_loss: 0.6197\n",
      "Epoch 775/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6295 - val_loss: 0.6482\n",
      "Epoch 776/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6301 - val_loss: 0.6179\n",
      "Epoch 777/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6294 - val_loss: 0.6289\n",
      "Epoch 778/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6298 - val_loss: 0.6244\n",
      "Epoch 779/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6296 - val_loss: 0.6489\n",
      "Epoch 780/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6297 - val_loss: 0.6429\n",
      "Epoch 781/1000\n",
      "58605/58605 [==============================] - 60s 1ms/step - loss: 0.6296 - val_loss: 0.6187\n",
      "Epoch 782/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6300 - val_loss: 0.6253\n",
      "Epoch 783/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6299 - val_loss: 0.6306\n",
      "Epoch 784/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6298 - val_loss: 0.6226\n",
      "Epoch 785/1000\n",
      "58605/58605 [==============================] - 56s 950us/step - loss: 0.6296 - val_loss: 0.6221\n",
      "Epoch 786/1000\n",
      "58605/58605 [==============================] - 55s 938us/step - loss: 0.6296 - val_loss: 0.6216\n",
      "Epoch 787/1000\n",
      "58605/58605 [==============================] - 55s 940us/step - loss: 0.6295 - val_loss: 0.6202\n",
      "Epoch 788/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6296 - val_loss: 0.6211\n",
      "Epoch 789/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6307 - val_loss: 0.6374\n",
      "Epoch 790/1000\n",
      "58605/58605 [==============================] - 57s 970us/step - loss: 0.6300 - val_loss: 0.6258\n",
      "Epoch 791/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6299 - val_loss: 0.6200\n",
      "Epoch 792/1000\n",
      "58605/58605 [==============================] - 56s 951us/step - loss: 0.6301 - val_loss: 0.6320\n",
      "Epoch 793/1000\n",
      "58605/58605 [==============================] - 56s 955us/step - loss: 0.6300 - val_loss: 0.6254\n",
      "Epoch 794/1000\n",
      "58605/58605 [==============================] - 56s 949us/step - loss: 0.6300 - val_loss: 0.6238\n",
      "Epoch 795/1000\n",
      "58605/58605 [==============================] - 56s 957us/step - loss: 0.6296 - val_loss: 0.6234\n",
      "Epoch 796/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6300 - val_loss: 0.6332\n",
      "Epoch 797/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6300 - val_loss: 0.6329\n",
      "Epoch 798/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6298 - val_loss: 0.6278\n",
      "Epoch 799/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6299 - val_loss: 0.6328\n",
      "Epoch 800/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6302 - val_loss: 0.6186\n",
      "Epoch 801/1000\n",
      "58605/58605 [==============================] - 56s 953us/step - loss: 0.6301 - val_loss: 0.6243\n",
      "Epoch 802/1000\n",
      "58605/58605 [==============================] - 55s 943us/step - loss: 0.6298 - val_loss: 0.6262\n",
      "Epoch 803/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6301 - val_loss: 0.6216\n",
      "Epoch 804/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6301 - val_loss: 0.6198\n",
      "Epoch 805/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6302 - val_loss: 0.6209\n",
      "Epoch 806/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6297 - val_loss: 0.6203\n",
      "Epoch 807/1000\n",
      "58605/58605 [==============================] - 56s 958us/step - loss: 0.6301 - val_loss: 0.6220\n",
      "Epoch 808/1000\n",
      "58605/58605 [==============================] - 56s 952us/step - loss: 0.6300 - val_loss: 0.6507\n",
      "Epoch 809/1000\n",
      "58605/58605 [==============================] - 55s 946us/step - loss: 0.6303 - val_loss: 0.6229\n",
      "Epoch 810/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6301 - val_loss: 0.6343\n",
      "Epoch 811/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6308 - val_loss: 0.6438\n",
      "Epoch 812/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6301 - val_loss: 0.6351\n",
      "Epoch 813/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6303 - val_loss: 0.6186\n",
      "Epoch 814/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6304 - val_loss: 0.6345\n",
      "Epoch 815/1000\n",
      "58605/58605 [==============================] - 56s 956us/step - loss: 0.6306 - val_loss: 0.6235\n",
      "Epoch 816/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6301 - val_loss: 0.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 817/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6302 - val_loss: 0.6358\n",
      "Epoch 818/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6306 - val_loss: 0.6269\n",
      "Epoch 819/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6306 - val_loss: 0.6340\n",
      "Epoch 820/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6302 - val_loss: 0.6218\n",
      "Epoch 821/1000\n",
      "58605/58605 [==============================] - 57s 974us/step - loss: 0.6300 - val_loss: 0.6327\n",
      "Epoch 822/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6302 - val_loss: 0.6316\n",
      "Epoch 823/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6305 - val_loss: 0.6379\n",
      "Epoch 824/1000\n",
      "58605/58605 [==============================] - 57s 972us/step - loss: 0.6301 - val_loss: 0.6392\n",
      "Epoch 825/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6304 - val_loss: 0.6202\n",
      "Epoch 826/1000\n",
      "58605/58605 [==============================] - 57s 969us/step - loss: 0.6302 - val_loss: 0.6335\n",
      "Epoch 827/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6304 - val_loss: 0.6519\n",
      "Epoch 828/1000\n",
      "58605/58605 [==============================] - 57s 971us/step - loss: 0.6302 - val_loss: 0.6253\n",
      "Epoch 829/1000\n",
      "58605/58605 [==============================] - 57s 968us/step - loss: 0.6305 - val_loss: 0.6428\n",
      "Epoch 830/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6305 - val_loss: 0.6349\n",
      "Epoch 831/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6308 - val_loss: 0.6375\n",
      "Epoch 832/1000\n",
      "58605/58605 [==============================] - 57s 973us/step - loss: 0.6305 - val_loss: 0.6219\n",
      "Epoch 833/1000\n",
      "58605/58605 [==============================] - 56s 948us/step - loss: 0.6302 - val_loss: 0.6530\n",
      "Epoch 834/1000\n",
      "58605/58605 [==============================] - 55s 945us/step - loss: 0.6303 - val_loss: 0.6245\n",
      "Epoch 835/1000\n",
      "58605/58605 [==============================] - 55s 944us/step - loss: 0.6307 - val_loss: 0.6220\n",
      "Epoch 836/1000\n",
      "58605/58605 [==============================] - 55s 944us/step - loss: 0.6304 - val_loss: 0.6232\n",
      "Epoch 837/1000\n",
      "58605/58605 [==============================] - 55s 939us/step - loss: 0.6307 - val_loss: 0.6364\n",
      "Epoch 838/1000\n",
      "58605/58605 [==============================] - 56s 953us/step - loss: 0.6305 - val_loss: 0.6276\n",
      "Epoch 839/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6306 - val_loss: 0.6291\n",
      "Epoch 840/1000\n",
      "58605/58605 [==============================] - 56s 958us/step - loss: 0.6307 - val_loss: 0.6256\n",
      "Epoch 841/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6304 - val_loss: 0.6184\n",
      "Epoch 842/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6304 - val_loss: 0.6526\n",
      "Epoch 843/1000\n",
      "58605/58605 [==============================] - 56s 956us/step - loss: 0.6312 - val_loss: 0.6259\n",
      "Epoch 844/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6302 - val_loss: 0.6329\n",
      "Epoch 845/1000\n",
      "58605/58605 [==============================] - 56s 956us/step - loss: 0.6308 - val_loss: 0.6235\n",
      "Epoch 846/1000\n",
      "58605/58605 [==============================] - 55s 947us/step - loss: 0.6308 - val_loss: 0.6284\n",
      "Epoch 847/1000\n",
      "58605/58605 [==============================] - 56s 948us/step - loss: 0.6309 - val_loss: 0.6304\n",
      "Epoch 848/1000\n",
      "58605/58605 [==============================] - 56s 952us/step - loss: 0.6306 - val_loss: 0.6190\n",
      "Epoch 849/1000\n",
      "58605/58605 [==============================] - 56s 950us/step - loss: 0.6307 - val_loss: 0.6259\n",
      "Epoch 850/1000\n",
      "58605/58605 [==============================] - 55s 945us/step - loss: 0.6307 - val_loss: 0.6323\n",
      "Epoch 851/1000\n",
      "58605/58605 [==============================] - 56s 952us/step - loss: 0.6312 - val_loss: 0.6222\n",
      "Epoch 852/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6306 - val_loss: 0.6316\n",
      "Epoch 853/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6307 - val_loss: 0.6258\n",
      "Epoch 854/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6308 - val_loss: 0.6215\n",
      "Epoch 855/1000\n",
      "58605/58605 [==============================] - 56s 957us/step - loss: 0.6309 - val_loss: 0.6175\n",
      "Epoch 856/1000\n",
      "58605/58605 [==============================] - 56s 949us/step - loss: 0.6310 - val_loss: 0.6310\n",
      "Epoch 857/1000\n",
      "58605/58605 [==============================] - 55s 943us/step - loss: 0.6306 - val_loss: 0.6211\n",
      "Epoch 858/1000\n",
      "58605/58605 [==============================] - 55s 944us/step - loss: 0.6309 - val_loss: 0.6355\n",
      "Epoch 859/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6312 - val_loss: 0.6310\n",
      "Epoch 860/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6311 - val_loss: 0.6258\n",
      "Epoch 861/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6310 - val_loss: 0.6264\n",
      "Epoch 862/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6310 - val_loss: 0.6331\n",
      "Epoch 863/1000\n",
      "58605/58605 [==============================] - 56s 955us/step - loss: 0.6310 - val_loss: 0.6251\n",
      "Epoch 864/1000\n",
      "58605/58605 [==============================] - 56s 952us/step - loss: 0.6308 - val_loss: 0.6244\n",
      "Epoch 865/1000\n",
      "58605/58605 [==============================] - 55s 947us/step - loss: 0.6311 - val_loss: 0.6394\n",
      "Epoch 866/1000\n",
      "58605/58605 [==============================] - 56s 957us/step - loss: 0.6311 - val_loss: 0.6463\n",
      "Epoch 867/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6315 - val_loss: 0.6348\n",
      "Epoch 868/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6308 - val_loss: 0.6532\n",
      "Epoch 869/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6312 - val_loss: 0.6248\n",
      "Epoch 870/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6311 - val_loss: 0.6256\n",
      "Epoch 871/1000\n",
      "58605/58605 [==============================] - 56s 955us/step - loss: 0.6309 - val_loss: 0.6290\n",
      "Epoch 872/1000\n",
      "58605/58605 [==============================] - 56s 951us/step - loss: 0.6310 - val_loss: 0.6192\n",
      "Epoch 873/1000\n",
      "58605/58605 [==============================] - 56s 949us/step - loss: 0.6313 - val_loss: 0.6289\n",
      "Epoch 874/1000\n",
      "58605/58605 [==============================] - 56s 964us/step - loss: 0.6308 - val_loss: 0.6491\n",
      "Epoch 875/1000\n",
      "58605/58605 [==============================] - 57s 965us/step - loss: 0.6311 - val_loss: 0.6192\n",
      "Epoch 876/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6312 - val_loss: 0.6214\n",
      "Epoch 877/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6312 - val_loss: 0.6232\n",
      "Epoch 878/1000\n",
      "58605/58605 [==============================] - 56s 956us/step - loss: 0.6314 - val_loss: 0.6192\n",
      "Epoch 879/1000\n",
      "58605/58605 [==============================] - 56s 953us/step - loss: 0.6311 - val_loss: 0.6234\n",
      "Epoch 880/1000\n",
      "58605/58605 [==============================] - 56s 950us/step - loss: 0.6316 - val_loss: 0.6306\n",
      "Epoch 881/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6317 - val_loss: 0.6246\n",
      "Epoch 882/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6315 - val_loss: 0.6429\n",
      "Epoch 883/1000\n",
      "58605/58605 [==============================] - 57s 964us/step - loss: 0.6317 - val_loss: 0.6225\n",
      "Epoch 884/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6311 - val_loss: 0.6210\n",
      "Epoch 885/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6311 - val_loss: 0.6429\n",
      "Epoch 886/1000\n",
      "58605/58605 [==============================] - 56s 959us/step - loss: 0.6318 - val_loss: 0.6346\n",
      "Epoch 887/1000\n",
      "58605/58605 [==============================] - 56s 952us/step - loss: 0.6316 - val_loss: 0.6451\n",
      "Epoch 888/1000\n",
      "58605/58605 [==============================] - 56s 958us/step - loss: 0.6313 - val_loss: 0.6192\n",
      "Epoch 889/1000\n",
      "58605/58605 [==============================] - 57s 976us/step - loss: 0.6317 - val_loss: 0.6595\n",
      "Epoch 890/1000\n",
      "58605/58605 [==============================] - 57s 977us/step - loss: 0.6316 - val_loss: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "58605/58605 [==============================] - 56s 959us/step - loss: 0.6313 - val_loss: 0.6214\n",
      "Epoch 892/1000\n",
      "58605/58605 [==============================] - 56s 958us/step - loss: 0.6314 - val_loss: 0.6313\n",
      "Epoch 893/1000\n",
      "58605/58605 [==============================] - 56s 957us/step - loss: 0.6315 - val_loss: 0.6312\n",
      "Epoch 894/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6318 - val_loss: 0.6208\n",
      "Epoch 895/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6318 - val_loss: 0.6199\n",
      "Epoch 896/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6321 - val_loss: 0.6249\n",
      "Epoch 897/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6318 - val_loss: 0.6452\n",
      "Epoch 898/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6321 - val_loss: 0.6204\n",
      "Epoch 899/1000\n",
      "58605/58605 [==============================] - 56s 959us/step - loss: 0.6318 - val_loss: 0.6241\n",
      "Epoch 900/1000\n",
      "58605/58605 [==============================] - 56s 957us/step - loss: 0.6314 - val_loss: 0.6367\n",
      "Epoch 901/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6319 - val_loss: 0.6282\n",
      "Epoch 902/1000\n",
      "58605/58605 [==============================] - 56s 957us/step - loss: 0.6321 - val_loss: 0.6288\n",
      "Epoch 903/1000\n",
      "58605/58605 [==============================] - 56s 953us/step - loss: 0.6317 - val_loss: 0.6286\n",
      "Epoch 904/1000\n",
      "58605/58605 [==============================] - 56s 956us/step - loss: 0.6317 - val_loss: 0.6207\n",
      "Epoch 905/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6321 - val_loss: 0.6331\n",
      "Epoch 906/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6319 - val_loss: 0.6243\n",
      "Epoch 907/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6323 - val_loss: 0.6264\n",
      "Epoch 908/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6321 - val_loss: 0.6530\n",
      "Epoch 909/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6319 - val_loss: 0.6188\n",
      "Epoch 910/1000\n",
      "58605/58605 [==============================] - 56s 958us/step - loss: 0.6314 - val_loss: 0.6235\n",
      "Epoch 911/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6321 - val_loss: 0.6190\n",
      "Epoch 912/1000\n",
      "58605/58605 [==============================] - 57s 967us/step - loss: 0.6321 - val_loss: 0.6253\n",
      "Epoch 913/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6316 - val_loss: 0.6254\n",
      "Epoch 914/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6322 - val_loss: 0.6199\n",
      "Epoch 915/1000\n",
      "58605/58605 [==============================] - 56s 957us/step - loss: 0.6318 - val_loss: 0.6379\n",
      "Epoch 916/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6318 - val_loss: 0.6272\n",
      "Epoch 917/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6324 - val_loss: 0.6199\n",
      "Epoch 918/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6324 - val_loss: 0.6325\n",
      "Epoch 919/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6327 - val_loss: 0.6340\n",
      "Epoch 920/1000\n",
      "58605/58605 [==============================] - 56s 958us/step - loss: 0.6322 - val_loss: 0.6357\n",
      "Epoch 921/1000\n",
      "58605/58605 [==============================] - 57s 966us/step - loss: 0.6325 - val_loss: 0.6228\n",
      "Epoch 922/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6327 - val_loss: 0.6244\n",
      "Epoch 923/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6320 - val_loss: 0.6361\n",
      "Epoch 924/1000\n",
      "58605/58605 [==============================] - 56s 960us/step - loss: 0.6326 - val_loss: 0.6353\n",
      "Epoch 925/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6327 - val_loss: 0.6281\n",
      "Epoch 926/1000\n",
      "58605/58605 [==============================] - 56s 963us/step - loss: 0.6326 - val_loss: 0.6276\n",
      "Epoch 927/1000\n",
      "58605/58605 [==============================] - 56s 959us/step - loss: 0.6323 - val_loss: 0.6372\n",
      "Epoch 928/1000\n",
      "58605/58605 [==============================] - 56s 961us/step - loss: 0.6325 - val_loss: 0.6321\n",
      "Epoch 929/1000\n",
      "58605/58605 [==============================] - 56s 962us/step - loss: 0.6326 - val_loss: 0.6217\n",
      "Epoch 930/1000\n",
      "58605/58605 [==============================] - 56s 959us/step - loss: 0.6327 - val_loss: 0.6385\n",
      "Epoch 931/1000\n",
      "58605/58605 [==============================] - 59s 1ms/step - loss: 0.6324 - val_loss: 0.6316\n",
      "Epoch 932/1000\n",
      "58605/58605 [==============================] - 102s 2ms/step - loss: 0.6321 - val_loss: 0.6305\n",
      "Epoch 933/1000\n",
      "58605/58605 [==============================] - 106s 2ms/step - loss: 0.6323 - val_loss: 0.6278\n",
      "Epoch 934/1000\n",
      "58605/58605 [==============================] - 106s 2ms/step - loss: 0.6327 - val_loss: 0.6238\n",
      "Epoch 935/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6324 - val_loss: 0.6225\n",
      "Epoch 936/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6328 - val_loss: 0.6400\n",
      "Epoch 937/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6325 - val_loss: 0.6214\n",
      "Epoch 938/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6332 - val_loss: 0.6270\n",
      "Epoch 939/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6328 - val_loss: 0.6257\n",
      "Epoch 940/1000\n",
      "58605/58605 [==============================] - 81s 1ms/step - loss: 0.6332 - val_loss: 0.6257\n",
      "Epoch 941/1000\n",
      "58605/58605 [==============================] - 88s 2ms/step - loss: 0.6334 - val_loss: 0.6315\n",
      "Epoch 942/1000\n",
      "58605/58605 [==============================] - 86s 1ms/step - loss: 0.6332 - val_loss: 0.6282\n",
      "Epoch 943/1000\n",
      "58605/58605 [==============================] - 89s 2ms/step - loss: 0.6329 - val_loss: 0.6332\n",
      "Epoch 944/1000\n",
      "58605/58605 [==============================] - 87s 1ms/step - loss: 0.6335 - val_loss: 0.6552\n",
      "Epoch 945/1000\n",
      "58605/58605 [==============================] - 85s 1ms/step - loss: 0.6334 - val_loss: 0.6412\n",
      "Epoch 946/1000\n",
      "58605/58605 [==============================] - 88s 1ms/step - loss: 0.6336 - val_loss: 0.6347\n",
      "Epoch 947/1000\n",
      "58605/58605 [==============================] - 121s 2ms/step - loss: 0.6338 - val_loss: 0.6324\n",
      "Epoch 948/1000\n",
      "58605/58605 [==============================] - 124s 2ms/step - loss: 0.6334 - val_loss: 0.6404\n",
      "Epoch 949/1000\n",
      "58605/58605 [==============================] - 135s 2ms/step - loss: 0.6336 - val_loss: 0.6559\n",
      "Epoch 950/1000\n",
      "58605/58605 [==============================] - 104s 2ms/step - loss: 0.6335 - val_loss: 0.6347\n",
      "Epoch 951/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6336 - val_loss: 0.6410\n",
      "Epoch 952/1000\n",
      "58605/58605 [==============================] - 83s 1ms/step - loss: 0.6335 - val_loss: 0.6565\n",
      "Epoch 953/1000\n",
      "58605/58605 [==============================] - 84s 1ms/step - loss: 0.6339 - val_loss: 0.6320\n",
      "Epoch 954/1000\n",
      "58605/58605 [==============================] - 87s 1ms/step - loss: 0.6333 - val_loss: 0.6270\n",
      "Epoch 955/1000\n",
      "58605/58605 [==============================] - 87s 1ms/step - loss: 0.6344 - val_loss: 0.6291\n",
      "Epoch 956/1000\n",
      "58605/58605 [==============================] - 87s 1ms/step - loss: 0.6339 - val_loss: 0.6233\n",
      "Epoch 957/1000\n",
      "58605/58605 [==============================] - 88s 1ms/step - loss: 0.6354 - val_loss: 0.6242\n",
      "Epoch 958/1000\n",
      "58605/58605 [==============================] - 88s 1ms/step - loss: 0.6337 - val_loss: 0.6277\n",
      "Epoch 959/1000\n",
      "58605/58605 [==============================] - 86s 1ms/step - loss: 0.6336 - val_loss: 0.6306\n",
      "Epoch 960/1000\n",
      "58605/58605 [==============================] - 85s 1ms/step - loss: 0.6344 - val_loss: 0.6267\n",
      "Epoch 961/1000\n",
      "58605/58605 [==============================] - 85s 1ms/step - loss: 0.6344 - val_loss: 0.6273\n",
      "Epoch 962/1000\n",
      "58605/58605 [==============================] - 86s 1ms/step - loss: 0.6338 - val_loss: 0.6256\n",
      "Epoch 963/1000\n",
      "58605/58605 [==============================] - 85s 1ms/step - loss: 0.6343 - val_loss: 0.6242\n",
      "Epoch 964/1000\n",
      "58605/58605 [==============================] - 85s 1ms/step - loss: 0.6345 - val_loss: 0.6378\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58605/58605 [==============================] - 89s 2ms/step - loss: 0.6349 - val_loss: 0.6508\n",
      "Epoch 966/1000\n",
      "58605/58605 [==============================] - 98s 2ms/step - loss: 0.6352 - val_loss: 0.6355\n",
      "Epoch 967/1000\n",
      "58605/58605 [==============================] - 167s 3ms/step - loss: 0.6345 - val_loss: 0.6267\n",
      "Epoch 968/1000\n",
      "58605/58605 [==============================] - 149s 3ms/step - loss: 0.6348 - val_loss: 0.6382\n",
      "Epoch 969/1000\n",
      "58605/58605 [==============================] - 100s 2ms/step - loss: 0.6350 - val_loss: 0.6327\n",
      "Epoch 970/1000\n",
      "58605/58605 [==============================] - 103s 2ms/step - loss: 0.6352 - val_loss: 0.6240\n",
      "Epoch 971/1000\n",
      "58605/58605 [==============================] - 99s 2ms/step - loss: 0.6355 - val_loss: 0.6277\n",
      "Epoch 972/1000\n",
      "58605/58605 [==============================] - 104s 2ms/step - loss: 0.6343 - val_loss: 0.6395\n",
      "Epoch 973/1000\n",
      "58605/58605 [==============================] - 161s 3ms/step - loss: 0.6361 - val_loss: 0.6290\n",
      "Epoch 974/1000\n",
      "58605/58605 [==============================] - 308s 5ms/step - loss: 0.6362 - val_loss: 0.6570\n",
      "Epoch 975/1000\n",
      "58605/58605 [==============================] - 270s 5ms/step - loss: 0.6357 - val_loss: 0.6487\n",
      "Epoch 976/1000\n",
      "58605/58605 [==============================] - 329s 6ms/step - loss: 0.6375 - val_loss: 0.6389\n",
      "Epoch 977/1000\n",
      "58605/58605 [==============================] - 269s 5ms/step - loss: 0.6385 - val_loss: 0.6338\n",
      "Epoch 978/1000\n",
      "58605/58605 [==============================] - 101s 2ms/step - loss: 0.6356 - val_loss: 0.6326\n",
      "Epoch 979/1000\n",
      "58605/58605 [==============================] - 103s 2ms/step - loss: 0.6359 - val_loss: 0.6400\n",
      "Epoch 980/1000\n",
      "58605/58605 [==============================] - 108s 2ms/step - loss: 0.6352 - val_loss: 0.6378\n",
      "Epoch 981/1000\n",
      "58605/58605 [==============================] - 108s 2ms/step - loss: 0.6352 - val_loss: 0.6243\n",
      "Epoch 982/1000\n",
      "58605/58605 [==============================] - 1231s 21ms/step - loss: 0.6357 - val_loss: 0.6543\n",
      "Epoch 983/1000\n",
      "58605/58605 [==============================] - 177s 3ms/step - loss: 0.6361 - val_loss: 0.6242\n",
      "Epoch 984/1000\n",
      "58605/58605 [==============================] - 205s 3ms/step - loss: 0.6358 - val_loss: 0.6526\n",
      "Epoch 985/1000\n",
      "58605/58605 [==============================] - 162s 3ms/step - loss: 0.6371 - val_loss: 0.6209\n",
      "Epoch 986/1000\n",
      "58605/58605 [==============================] - 150s 3ms/step - loss: 0.6364 - val_loss: 0.6384\n",
      "Epoch 987/1000\n",
      "58605/58605 [==============================] - 202s 3ms/step - loss: 0.6366 - val_loss: 0.6299\n",
      "Epoch 988/1000\n",
      "58605/58605 [==============================] - 143s 2ms/step - loss: 0.6361 - val_loss: 0.6649\n",
      "Epoch 989/1000\n",
      "58605/58605 [==============================] - 145s 2ms/step - loss: 0.6365 - val_loss: 0.6287\n",
      "Epoch 990/1000\n",
      "58605/58605 [==============================] - 143s 2ms/step - loss: 0.6365 - val_loss: 0.6312\n",
      "Epoch 991/1000\n",
      "58605/58605 [==============================] - 137s 2ms/step - loss: 0.6364 - val_loss: 0.6506\n",
      "Epoch 992/1000\n",
      "58605/58605 [==============================] - 140s 2ms/step - loss: 0.6367 - val_loss: 0.6444\n",
      "Epoch 993/1000\n",
      "58605/58605 [==============================] - 143s 2ms/step - loss: 0.6371 - val_loss: 0.6376\n",
      "Epoch 994/1000\n",
      "58605/58605 [==============================] - 142s 2ms/step - loss: 0.6363 - val_loss: 0.6358\n",
      "Epoch 995/1000\n",
      "58605/58605 [==============================] - 144s 2ms/step - loss: 0.6365 - val_loss: 0.6418\n",
      "Epoch 996/1000\n",
      "58605/58605 [==============================] - 143s 2ms/step - loss: 0.6379 - val_loss: 0.6301\n",
      "Epoch 997/1000\n",
      "58605/58605 [==============================] - 143s 2ms/step - loss: 0.6384 - val_loss: 0.6519\n",
      "Epoch 998/1000\n",
      "58605/58605 [==============================] - 144s 2ms/step - loss: 0.6377 - val_loss: 0.6449\n",
      "Epoch 999/1000\n",
      "58605/58605 [==============================] - 146s 2ms/step - loss: 0.6369 - val_loss: 0.6422\n",
      "Epoch 1000/1000\n",
      "58605/58605 [==============================] - 134s 2ms/step - loss: 0.6371 - val_loss: 0.6556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb703044fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "autoencoder.fit(\n",
    "    img_gray, img_gray,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the decoded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can output some of the original images and corresponding decoded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAEyCAYAAAASkfoNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noEpERERERKQCHVSJiIiIiIhU8H90BN+10FluTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6f0fb2a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(n):\n",
    "    rand = np.random.randint(len(img_gray))\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(img_gray[i].reshape(32, 32), cmap='gray')\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(pred[i].reshape(32, 32), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of original and decoded images created with a convolutional autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the decoded images from the previous chapter, our output has improved significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
