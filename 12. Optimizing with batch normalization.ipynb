{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing with batch normalization\n",
    "Another well-known optimization technique for CNNs is batch normalization. This technique normalizes the inputs of the current batch before feeding it to the next layer; therefore, the mean activation for each batch is around zero and the standard deviation around one, and we can avoid internal covariate shift.<br><br>\n",
    "By doing this, the input distribution of the data per batch has less effect on the network, and as a consequence the model is able to generalize better and train faster. <br><br>\n",
    "In the following example, we apply batch normalization to an image dataset with 10 classes (CIFAR-10). First, we train the network architecture without batch normalization to demonstrate the difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cifar10 datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_val, y_val) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255.\n",
    "X_val = X_val.astype('float32')/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_val = np_utils.to_categorical(y_val, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the CNN architecture and output the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,403,050\n",
      "Trainable params: 1,403,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train[0].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a callback to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=5, verbose=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set network hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 653s 13ms/step - loss: 1.8134 - acc: 0.3212 - val_loss: 1.4383 - val_acc: 0.4614\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 636s 13ms/step - loss: 1.3444 - acc: 0.5087 - val_loss: 1.1246 - val_acc: 0.5989\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 642s 13ms/step - loss: 1.1222 - acc: 0.5966 - val_loss: 1.1822 - val_acc: 0.5831\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 642s 13ms/step - loss: 0.9952 - acc: 0.6474 - val_loss: 0.9055 - val_acc: 0.6827\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 644s 13ms/step - loss: 0.9080 - acc: 0.6777 - val_loss: 0.8097 - val_acc: 0.7147\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 648s 13ms/step - loss: 0.8360 - acc: 0.7045 - val_loss: 0.7957 - val_acc: 0.7156\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 635s 13ms/step - loss: 0.7709 - acc: 0.7299 - val_loss: 0.7829 - val_acc: 0.7285\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 634s 13ms/step - loss: 0.7210 - acc: 0.7450 - val_loss: 0.6966 - val_acc: 0.7572\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 639s 13ms/step - loss: 0.6833 - acc: 0.7600 - val_loss: 0.6704 - val_acc: 0.7673\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 641s 13ms/step - loss: 0.6429 - acc: 0.7736 - val_loss: 0.6445 - val_acc: 0.7812\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 620s 12ms/step - loss: 0.6049 - acc: 0.7875 - val_loss: 0.6780 - val_acc: 0.7637\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 620s 12ms/step - loss: 0.5814 - acc: 0.7936 - val_loss: 0.5956 - val_acc: 0.7970\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 621s 12ms/step - loss: 0.5510 - acc: 0.8051 - val_loss: 0.6177 - val_acc: 0.7911\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 618s 12ms/step - loss: 0.5288 - acc: 0.8157 - val_loss: 0.5767 - val_acc: 0.8081\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 616s 12ms/step - loss: 0.5062 - acc: 0.8222 - val_loss: 0.6263 - val_acc: 0.7930\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 619s 12ms/step - loss: 0.4920 - acc: 0.8260 - val_loss: 0.5787 - val_acc: 0.8018\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 622s 12ms/step - loss: 0.4674 - acc: 0.8350 - val_loss: 0.5714 - val_acc: 0.8042\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 617s 12ms/step - loss: 0.4547 - acc: 0.8379 - val_loss: 0.6177 - val_acc: 0.7982\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 621s 12ms/step - loss: 0.4401 - acc: 0.8446 - val_loss: 0.5903 - val_acc: 0.8073\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(X_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add batch normalization to our network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,406,890\n",
      "Trainable params: 1,404,970\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bn = Sequential()\n",
    "\n",
    "model_bn.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_bn.add(Dropout(0.25))\n",
    "\n",
    "model_bn.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_bn.add(Dropout(0.25))\n",
    "\n",
    "model_bn.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model_bn.add(Activation('relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_bn.add(Dropout(0.25))\n",
    "\n",
    "model_bn.add(Flatten())\n",
    "model_bn.add(Dense(512, activation='relu'))\n",
    "model_bn.add(BatchNormalization())\n",
    "model_bn.add(Dropout(0.5))\n",
    "model_bn.add(Dense(128, activation='relu'))\n",
    "model_bn.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_bn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_bn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model that includes batchnormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "50000/50000 [==============================] - 841s 17ms/step - loss: 1.6458 - acc: 0.4244 - val_loss: 3.6049 - val_acc: 0.1610\n",
      "Epoch 2/300\n",
      "50000/50000 [==============================] - 899s 18ms/step - loss: 1.1702 - acc: 0.5816 - val_loss: 2.8794 - val_acc: 0.2465\n",
      "Epoch 3/300\n",
      "50000/50000 [==============================] - 757s 15ms/step - loss: 0.9783 - acc: 0.6534 - val_loss: 1.1287 - val_acc: 0.6128\n",
      "Epoch 4/300\n",
      "50000/50000 [==============================] - 788s 16ms/step - loss: 0.8462 - acc: 0.7022 - val_loss: 0.8321 - val_acc: 0.7130\n",
      "Epoch 5/300\n",
      "50000/50000 [==============================] - 1234s 25ms/step - loss: 0.7543 - acc: 0.7363 - val_loss: 0.8076 - val_acc: 0.7217\n",
      "Epoch 6/300\n",
      "50000/50000 [==============================] - 2484s 50ms/step - loss: 0.6946 - acc: 0.7558 - val_loss: 0.7145 - val_acc: 0.7518\n",
      "Epoch 7/300\n",
      "50000/50000 [==============================] - 1763s 35ms/step - loss: 0.6350 - acc: 0.7755 - val_loss: 0.6306 - val_acc: 0.7820\n",
      "Epoch 8/300\n",
      "50000/50000 [==============================] - 1418s 28ms/step - loss: 0.5840 - acc: 0.7930 - val_loss: 0.6027 - val_acc: 0.7904\n",
      "Epoch 9/300\n",
      "50000/50000 [==============================] - 1196s 24ms/step - loss: 0.5500 - acc: 0.8062 - val_loss: 0.6410 - val_acc: 0.7897\n",
      "Epoch 10/300\n",
      "50000/50000 [==============================] - 1142s 23ms/step - loss: 0.5135 - acc: 0.8214 - val_loss: 0.5933 - val_acc: 0.7987\n",
      "Epoch 11/300\n",
      "50000/50000 [==============================] - 1159s 23ms/step - loss: 0.4811 - acc: 0.8301 - val_loss: 0.5542 - val_acc: 0.8118\n",
      "Epoch 12/300\n",
      "50000/50000 [==============================] - 1151s 23ms/step - loss: 0.4543 - acc: 0.8407 - val_loss: 0.5780 - val_acc: 0.8095\n",
      "Epoch 13/300\n",
      "50000/50000 [==============================] - 1145s 23ms/step - loss: 0.4205 - acc: 0.8513 - val_loss: 0.5887 - val_acc: 0.8076\n",
      "Epoch 14/300\n",
      "50000/50000 [==============================] - 1154s 23ms/step - loss: 0.4003 - acc: 0.8573 - val_loss: 0.5326 - val_acc: 0.8327\n",
      "Epoch 15/300\n",
      "50000/50000 [==============================] - 1133s 23ms/step - loss: 0.3769 - acc: 0.8673 - val_loss: 0.5250 - val_acc: 0.8329\n",
      "Epoch 16/300\n",
      "50000/50000 [==============================] - 1148s 23ms/step - loss: 0.3606 - acc: 0.8734 - val_loss: 0.5301 - val_acc: 0.8291\n",
      "Epoch 17/300\n",
      "50000/50000 [==============================] - 1147s 23ms/step - loss: 0.3431 - acc: 0.8785 - val_loss: 0.5448 - val_acc: 0.8244\n",
      "Epoch 18/300\n",
      "50000/50000 [==============================] - 1136s 23ms/step - loss: 0.3265 - acc: 0.8838 - val_loss: 0.5444 - val_acc: 0.8315\n",
      "Epoch 19/300\n",
      "50000/50000 [==============================] - 1144s 23ms/step - loss: 0.3087 - acc: 0.8906 - val_loss: 0.6008 - val_acc: 0.8148\n",
      "Epoch 20/300\n",
      "50000/50000 [==============================] - 1151s 23ms/step - loss: 0.2917 - acc: 0.8957 - val_loss: 0.5130 - val_acc: 0.8408\n",
      "Epoch 21/300\n",
      "50000/50000 [==============================] - 1138s 23ms/step - loss: 0.2813 - acc: 0.8997 - val_loss: 0.5874 - val_acc: 0.8204\n",
      "Epoch 22/300\n",
      "50000/50000 [==============================] - 1156s 23ms/step - loss: 0.2630 - acc: 0.9066 - val_loss: 0.5089 - val_acc: 0.8447\n",
      "Epoch 23/300\n",
      "50000/50000 [==============================] - 1145s 23ms/step - loss: 0.2559 - acc: 0.9088 - val_loss: 0.5587 - val_acc: 0.8297\n",
      "Epoch 24/300\n",
      "50000/50000 [==============================] - 1140s 23ms/step - loss: 0.2518 - acc: 0.9102 - val_loss: 0.4992 - val_acc: 0.8496\n",
      "Epoch 25/300\n",
      "50000/50000 [==============================] - 1158s 23ms/step - loss: 0.2351 - acc: 0.9152 - val_loss: 0.5771 - val_acc: 0.8334\n",
      "Epoch 26/300\n",
      "50000/50000 [==============================] - 1154s 23ms/step - loss: 0.2325 - acc: 0.9169 - val_loss: 0.5422 - val_acc: 0.8404\n",
      "Epoch 27/300\n",
      "50000/50000 [==============================] - 1148s 23ms/step - loss: 0.2230 - acc: 0.9198 - val_loss: 0.5439 - val_acc: 0.8413\n",
      "Epoch 28/300\n",
      "50000/50000 [==============================] - 1160s 23ms/step - loss: 0.2127 - acc: 0.9245 - val_loss: 0.5223 - val_acc: 0.8478\n",
      "Epoch 29/300\n",
      "50000/50000 [==============================] - 1153s 23ms/step - loss: 0.2109 - acc: 0.9243 - val_loss: 0.5595 - val_acc: 0.8382\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    " history_bn = model_bn.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the validation accuracy of both models to compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36be8e4160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc_bn = history_bn.history['val_acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(range(len(val_acc)), val_acc, label='CNN model')\n",
    "plt.plot(range(len(val_acc_bn)), val_acc_bn, label='CNN model with BN')\n",
    "plt.title('Validation accuracy on Cifar10 dataset')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing validation accuracy of a model with and without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8496 0.8081\n",
      "29 19\n"
     ]
    }
   ],
   "source": [
    "print(max(val_acc_bn), max(val_acc))\n",
    "print(len(val_acc_bn), len(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model with batch normalization takes the leadon validation accuracy after a couple of epochs and manages to stay ahead of the model without batch normalization, with a maximum validation accuracy of 84.16%, compared to a validation accuracy of 83.19% for the model without batch normalization. The model with batch normalization also converges faster (26 epochs vs 40 epochs). However, with 25 seconds per epoch, the model with batch normalization is slightly slower per epoch than the model without batch normalization (17 seconds)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
