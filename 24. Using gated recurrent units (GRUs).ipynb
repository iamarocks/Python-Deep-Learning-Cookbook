{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using gated recurrent units (GRUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another type of unit often used in RNNs is gated recurrent units (GRUs). These units are actually simpler than LSTM units, because they only have two gates: update and reset. The update gate determines the memory and the reset gate combines the memory with the current input. The flow of data is made visual in the following figure:\n",
    "\n",
    "![alt text][logo]\n",
    "\n",
    "[logo]:https://github.com/sara-kassani/Python-Deep-Learning-Cookbook/blob/master/data/GRU.png?raw=true \"Using gated recurrent units\"\n",
    "In this recipe, we will show how to incorporate a GRU into an RNN architecture to classify text with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using the IMDb dataset that classifies the sentiment of text; load the data with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seq: 25000\n",
      "Test seq: 25000\n"
     ]
    }
   ],
   "source": [
    "n_words = 1000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=n_words)\n",
    "print('Train seq: {}'.format(len(X_train)))\n",
    "print('Test seq: {}'.format(len(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By padding the sequences, we prepare our input for our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pad sequences with max_len\n",
    "max_len = 200\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network architecture and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 50)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 100)               45300     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               25250     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 120,801\n",
      "Trainable params: 120,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define network architecture and compile\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_words, 50, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use early stopping to prevent overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyperparameters and start training our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 111s 6ms/step - loss: 0.6705 - acc: 0.5764 - val_loss: 0.5748 - val_acc: 0.6932\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 106s 5ms/step - loss: 0.5327 - acc: 0.7339 - val_loss: 0.5225 - val_acc: 0.7344\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 80s 4ms/step - loss: 0.4920 - acc: 0.7631 - val_loss: 0.4860 - val_acc: 0.7562\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 82s 4ms/step - loss: 0.4594 - acc: 0.7873 - val_loss: 0.4860 - val_acc: 0.7616\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.4425 - acc: 0.8021 - val_loss: 0.4549 - val_acc: 0.7856\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 130s 6ms/step - loss: 0.4303 - acc: 0.8115 - val_loss: 0.4548 - val_acc: 0.7904\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 96s 5ms/step - loss: 0.4109 - acc: 0.8197 - val_loss: 0.4633 - val_acc: 0.7906\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 109s 5ms/step - loss: 0.4234 - acc: 0.8165 - val_loss: 0.4188 - val_acc: 0.8112\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 114s 6ms/step - loss: 0.3916 - acc: 0.8319 - val_loss: 0.4098 - val_acc: 0.8148\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 110s 5ms/step - loss: 0.3857 - acc: 0.8337 - val_loss: 0.4025 - val_acc: 0.8200\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 112s 6ms/step - loss: 0.3776 - acc: 0.8381 - val_loss: 0.4309 - val_acc: 0.8040\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 112s 6ms/step - loss: 0.3811 - acc: 0.8361 - val_loss: 0.3924 - val_acc: 0.8290\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 111s 6ms/step - loss: 0.3566 - acc: 0.8497 - val_loss: 0.3845 - val_acc: 0.8380\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 112s 6ms/step - loss: 0.3536 - acc: 0.8508 - val_loss: 0.3685 - val_acc: 0.8488\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 100s 5ms/step - loss: 0.3597 - acc: 0.8465 - val_loss: 0.4064 - val_acc: 0.8292\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 78s 4ms/step - loss: 0.3506 - acc: 0.8488 - val_loss: 0.3824 - val_acc: 0.8400\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 80s 4ms/step - loss: 0.3402 - acc: 0.8536 - val_loss: 0.3682 - val_acc: 0.8470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f256d731630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "n_epochs = 100\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the performance of our trained network on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 43s 2ms/step\n",
      "Accuracy on test set: 0.84812\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test set: {}'.format(model.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "# Accuracy on test set: 0.83004"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
