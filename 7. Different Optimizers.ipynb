{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Optimizers\n",
    "The most popular and well known optimizer is Stochastic Gradient Descent (SGD). This technique is widely used in other machine learning models as well. SGD is a method to find minima or maxima by iteration. There are many popular variants of SGD that try to speed up convergence and less tuning by using an adaptive learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adadelta, Adam, RMSprop, Adagrad, Nadam, Adamax\n",
    "\n",
    "SEED = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import the dataset and extract the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "y = data['quality']\n",
    "X = data.drop(['quality'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that creates the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(opt): \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that defines callbacks we will be using during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_callbacks(opt):\n",
    "    callbacks = [\n",
    "    EarlyStopping(monitor='val_acc', patience=200, verbose=2),\n",
    "    ModelCheckpoint('data/optimizers_best_' + opt + '.h5', monitor='val_acc', save_best_only=True, verbose=0)\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dict of the optimizers we want to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opts = dict({\n",
    "    'sgd': SGD(),\n",
    "     'sgd-0001': SGD(lr=0.0001, decay=0.00001),\n",
    "     'adam': Adam(),\n",
    "     'adadelta': Adadelta(),\n",
    "     'rmsprop': RMSprop(),\n",
    "     'rmsprop-0001': RMSprop(lr=0.0001),\n",
    "     'nadam': Nadam(),\n",
    "     'adamax': Adamax()\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our networks and store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00201: early stopping\n",
      "Epoch 00422: early stopping\n",
      "Epoch 00393: early stopping\n",
      "Epoch 00471: early stopping\n",
      "Epoch 00450: early stopping\n",
      "Epoch 00484: early stopping\n",
      "Epoch 00292: early stopping\n",
      "Epoch 00455: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 1000\n",
    "\n",
    "results = []\n",
    "# Loop through the optimizers\n",
    "for opt in opts:\n",
    "    model = create_model(opt)\n",
    "    callbacks = create_callbacks(opt)\n",
    "    model.compile(loss='mse', optimizer=opts[opt], metrics=['accuracy'])\n",
    "    hist = model.fit(X_train.values, y_train, batch_size=batch_size, epochs=n_epochs, validation_data=(X_val.values, y_val), verbose=0,\n",
    "    callbacks=callbacks)\n",
    "    best_epoch = np.argmax(hist.history['val_acc'])\n",
    "    best_acc = hist.history['val_acc'][best_epoch] \n",
    "    best_model = create_model(opt)\n",
    "    # Load the model weights with the highest validation accuracy \n",
    "    best_model.load_weights('data/optimizers_best_' + opt + '.h5')\n",
    "    best_model.compile(loss='mse', optimizer=opts[opt], metrics=['accuracy'])\n",
    "    score = best_model.evaluate(X_test.values, y_test, verbose=0)\n",
    "    results.append([opt, best_epoch, best_acc, score[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>epochs</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sgd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sgd-0001</td>\n",
       "      <td>221</td>\n",
       "      <td>0.566406</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam</td>\n",
       "      <td>192</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adadelta</td>\n",
       "      <td>270</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.568750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>249</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.590625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rmsprop-0001</td>\n",
       "      <td>283</td>\n",
       "      <td>0.574219</td>\n",
       "      <td>0.581250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nadam</td>\n",
       "      <td>91</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.571875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adamax</td>\n",
       "      <td>254</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.603125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      optimizer  epochs  val_accuracy  test_accuracy\n",
       "0           sgd       0      0.000000       0.000000\n",
       "1      sgd-0001     221      0.566406       0.593750\n",
       "2          adam     192      0.589844       0.593750\n",
       "3      adadelta     270      0.582031       0.568750\n",
       "4       rmsprop     249      0.578125       0.590625\n",
       "5  rmsprop-0001     283      0.574219       0.581250\n",
       "6         nadam      91      0.578125       0.571875\n",
       "7        adamax     254      0.585938       0.603125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(results)\n",
    "res.columns = ['optimizer', 'epochs', 'val_accuracy', 'test_accuracy']\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of training with different optimizers on the Wine Quality dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
